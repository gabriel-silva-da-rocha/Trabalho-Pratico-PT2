{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a1cDXl7NwDb"
      },
      "source": [
        "# Classificação de Tumores Cerebrais com YOLOv11 e Faster R-CNN\n",
        "\n",
        "**Autores:** Beatriz Correia Santos, Gabriel Silva da Rocha\n",
        "\n",
        "**Curso:** Mestrado Profissional em Engenharia Elétrica – UEA  \n",
        "\n",
        "**Data:** Novembro/2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kgxX_zoPlJO"
      },
      "source": [
        "# **INTRODUÇÃO**\n",
        "Na prática clínica neuro-oncológica, a ressonância magnética (RM) é a\n",
        "modalidade de imagem padrão-ouro para a detecção, caracterização e acompanhamento de tumores cerebrais. No entanto, a interpretação desses exames é uma tarefa complexa, tempo-intensiva e inerentemente dependente da experiência do especialista, estando suscetível à variabilidade inter-observador. A demanda crescente por exames de imagem, aliada à necessidade de diagnósticos rápidos e precisos, expõe a limitação do fluxo de trabalho manual, onde a fadiga pode levar a falsos-negativos ou erros de classificação da lesão. Um diagnóstico incorreto ou tardio impacta diretamente o prognóstico do paciente e a definição do plano terapêutico adequado.\n",
        "\n",
        "Este estudo visa mitigar tais desafios através do desenvolvimento de um sistema automatizado para a classificação de imagens de RM cerebral em quatro principais categorias: glioma, meningioma, pituitário e \"sem tumor\". O uso da aplicação de Deep Learning (DL) fundamenta-se na capacidade comprovada das Redes Neurais Convolucionais (CNNs) em atuar como extratores robustos de características, aprendendo hierarquias complexas de padrões visuais diretamente dos dados. Modelos de DL podem identificar texturas e morfologias sutis, muitas vezes imperceptíveis ao olho humano, oferecendo um potencial significativo para aumentar a acurácia, a velocidade e a objetividade do diagnóstico, servindo como uma ferramenta poderosa de suporte à decisão clínica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m1Mh31jTYki"
      },
      "source": [
        "# **TRABALHOS RELACIONADOS**\n",
        "A detecção e classificação de tumores cerebrais a partir de imagens de ressonância magnética têm sido amplamente estudadas na literatura recente. As abordagens tradicionais de Computer Vision vêm sendo substituídas por modelos de Deep Learning, que apresentam melhor capacidade de generalização e extração de padrões complexos.\n",
        "\n",
        "Diversos estudos recentes utilizam o mesmo conjunto de dados empregado neste trabalho — o dataset de ressonâncias magnéticas cerebrais com quatro classes (Glioma, Meningioma, Pituitária e Sem Tumor) — evidenciando sua ampla adoção na pesquisa científica. Trabalhos como os de [Noori et al.](https://ieeexplore.ieee.org/abstract/document/10836556) (2024) e [Anwar et al.](https://ieeexplore.ieee.org/abstract/document/10890954) (2025) aplicaram técnicas de transfer learning em modelos ResNet50V2, VGG16, InceptionV3 e DenseNet121, alcançando acurácias entre 94% e 95% e F1-scores superiores a 0,93, confirmando a viabilidade desse dataset para tarefas de classificação e sua representatividade nas investigações da área médica.\n",
        "\n",
        "De forma semelhante, [Krolik et al.](https://arxiv.org/html/2510.10250v1) (2025) exploraram abordagens híbridas que combinam classification, segmentation e object detection utilizando arquiteturas como U-Net e EfficientDet, reforçando o potencial de modelos de detecção aplicados à identificação de tumores cerebrais. O presente trabalho segue essa mesma linha, adotando as arquiteturas YOLOv11 e Faster R-CNN para realizar a detecção e posterior classificação de tumores, baseando-se também no estudo prático de [Nuruzzaman](https://www.kaggle.com/code/nuruzzamannuru/brain-tumor-yolov11-and-custom-cnn) (2025), que propôs um pipeline semelhante com YOLO e CNN personalizados para o mesmo tipo de dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfHnLs3aGiTw",
        "outputId": "a4a3751e-4a70-43de-94fa-b076ba24072b"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "masoudnickparvar_brain_tumor_mri_dataset_path = kagglehub.dataset_download('masoudnickparvar/brain-tumor-mri-dataset')\n",
        "ahmedsorour1_mri_for_brain_tumor_with_bounding_boxes_path = kagglehub.dataset_download('ahmedsorour1/mri-for-brain-tumor-with-bounding-boxes')\n",
        "gabrielrocha2_duplicatas_path = kagglehub.dataset_download('gabrielrocha2/duplicatas')\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-89S-qUZwpQ"
      },
      "source": [
        "# **METODOLOGIA**\n",
        "\n",
        "O dataset escolhido foi o [Brain Tumor MRI Dataset](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset), por Masoud Nickparvar que é composto por três fontes distintas de imagens de ressonância magnética. Cada uma das três fontes trata as imagens de formas diferentes, sendo uma das fontes contendo apenas imagens com os três tipos de tumores rotulados, uma outra fonte apenas com imagens rotuladas como “com tumor” e “sem tumor”, e a outra fonte contendo imagens rotuladas com os três tipos de tumor e sem tumor também.\n",
        "O conjunto de dados contém pouco mais de sete mil imagens divididas em quatro classes, nas quais estão separadas em diretórios para treino e testes de modelos. As classes são: Glioma ( ~23%), Sem Tumor ( ~29%), Pituitary ( ~24%), Meningioma  ( ~23%). Com isso, as classes estão com um pequeno desbalanceamento. As imagens estão divididas em aproximadamente 81% para treino e 19% para testes.\n",
        "\n",
        "Para a aplicação do modelo YOLO é necessário ter todas as imagens com suas respectivas identificações de ocorrências através de caixas (bounding boxes) para que o treinamento do modelo seja feito. Para isso, foi utilizado o dataset [MRI for Brain Tumor with Bounding Boxes](https://www.kaggle.com/datasets/ahmedsorour1/mri-for-brain-tumor-with-bounding-boxes), que foi desenvolvido baseado no primeiro dataset apresentado, porém com suas devidas *labels* em formato YOLO.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9XrnBX5cjHF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function for importing data\n",
        "def get_data_labels(directory, shuffle=True, random_state=0):\n",
        "    \"\"\"\n",
        "    Function used for going into the main training directory\n",
        "    whose directory has sub-class-types.\n",
        "    \"\"\"\n",
        "    from sklearn.utils import shuffle\n",
        "    import os\n",
        "\n",
        "    # Lists to store data and labels\n",
        "    data_path = []\n",
        "    data_labels = []\n",
        "\n",
        "    for label in os.listdir(directory):\n",
        "        label_dir = os.path.join(directory, label)\n",
        "\n",
        "        # Avoid MacOS storing path\n",
        "        if not os.path.isdir(label_dir):\n",
        "            continue\n",
        "\n",
        "        # Going into each folder and getting image path\n",
        "        for image in os.listdir(label_dir):\n",
        "            image_path = os.path.join(label_dir, image)\n",
        "            data_path.append(image_path)\n",
        "            data_labels.append(label)\n",
        "\n",
        "    if shuffle:\n",
        "        data_path, data_labels = shuffle(data_path, data_labels, random_state=random_state)\n",
        "\n",
        "    return data_path, data_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPFaynlFoxnN"
      },
      "source": [
        "# **DISTRIBUIÇÃO DO DATASET ORIGINAL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "Ls858wbPb9-I",
        "outputId": "d174a6f6-52fd-4d20-d402-9e9b9162b82f"
      },
      "outputs": [],
      "source": [
        "# Setting up file paths for training and testing\n",
        "USER_PATH = masoudnickparvar_brain_tumor_mri_dataset_path\n",
        "train_dir = USER_PATH + r'/Training/'\n",
        "test_dir = USER_PATH + r'/Testing/'\n",
        "CLASS_TYPES = ['pituitary', 'notumor', 'meningioma', 'glioma']\n",
        "N_TYPES = len(CLASS_TYPES)\n",
        "\n",
        "# Getting data using above function\n",
        "train_paths, train_labels = get_data_labels(train_dir)\n",
        "test_paths, test_labels = get_data_labels(test_dir)\n",
        "\n",
        "# Printing traing and testing sample sizes\n",
        "print('Training')\n",
        "print(f'Number of Paths: {len(train_paths)}')\n",
        "print(f'Number of Labels: {len(train_labels)}')\n",
        "print('\\nTesting')\n",
        "print(f'Number of Paths: {len(test_paths)}')\n",
        "print(f'Number of Labels: {len(test_labels)}')\n",
        "\n",
        "_, ax = plt.subplots(ncols=3, figsize=(20, 14))\n",
        "\n",
        "# Plotting training data types\n",
        "class_counts = [len([x for x in train_labels if x == label]) for label in CLASS_TYPES]\n",
        "print('Training Counts')\n",
        "print(dict(zip(CLASS_TYPES, class_counts)))\n",
        "\n",
        "ax[0].set_title('Dados de Treino')\n",
        "ax[0].pie(\n",
        "    class_counts,\n",
        "    labels=[label.title() for label in CLASS_TYPES],\n",
        "    colors=['#FAC500','#0BFA00', '#0066FA','#FA0000'],\n",
        "    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum(class_counts) / 100),\n",
        "    explode=tuple(0.01 for i in range(N_TYPES)),\n",
        "    textprops={'fontsize': 20}\n",
        ")\n",
        "\n",
        "# Plotting testing data types\n",
        "class_counts = [len([x for x in test_labels if x == label]) for label in CLASS_TYPES]\n",
        "print('\\nTesting Counts')\n",
        "print(dict(zip(CLASS_TYPES, class_counts)))\n",
        "\n",
        "ax[1].set_title('Dados de Teste')\n",
        "ax[1].pie(\n",
        "    class_counts,\n",
        "    labels=[label.title() for label in CLASS_TYPES],\n",
        "    colors=['#FAC500', '#0BFA00', '#0066FA', '#FA0000'],\n",
        "    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum(class_counts) / 100),\n",
        "    explode=tuple(0.01 for i in range(N_TYPES)),  # Explode the slices slightly for better visualization\n",
        "    textprops={'fontsize': 20}  # Set the font size for the text on the pie chart\n",
        ")\n",
        "\n",
        "# Plotting distribution of train test split\n",
        "ax[2].set_title('Split Treino/Teste')\n",
        "ax[2].pie(\n",
        "    [len(train_labels), len(test_labels)],\n",
        "    labels=['Train','Test'],\n",
        "    colors=['darkcyan', 'orange'],\n",
        "    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum([len(train_labels), len(test_labels)]) / 100),\n",
        "    explode=(0.1, 0),\n",
        "    startangle=85,\n",
        "    textprops={'fontsize': 20}\n",
        ")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "kEBFmypjotV2",
        "outputId": "f84bf5df-0c67-4170-ad1f-23d608d79b34"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Junta os rótulos de treino e teste\n",
        "all_labels = list(train_labels) + list(test_labels)\n",
        "\n",
        "# Conta as ocorrências de cada classe\n",
        "class_counts = [all_labels.count(label) for label in CLASS_TYPES]\n",
        "\n",
        "print('Total Counts (Train+Test)')\n",
        "print(dict(zip(CLASS_TYPES, class_counts)))\n",
        "\n",
        "# Gráfico de pizza único\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.set_title('Distribuição de Classes')\n",
        "ax.pie(\n",
        "    class_counts,\n",
        "    labels=[label.title() for label in CLASS_TYPES],\n",
        "    colors=['#FAC500','#0BFA00','#0066FA','#FA0000'],\n",
        "    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum(class_counts) / 100),\n",
        "    explode=tuple(0.02 for _ in CLASS_TYPES),\n",
        "    textprops={'fontsize': 16}\n",
        ")\n",
        "ax.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK48sqBtbStO"
      },
      "source": [
        "# **PROBLEMAS ENCONTRADOS**\n",
        "\n",
        "Foram reportados problemas com duplicatas nos datasets escolhidos, para isso deve ser feito um trabalho de identificação das duplicatas e tratamento para remoção das mesmas, de forma a não impactar no treinamento dos modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nduOYBICI8I"
      },
      "source": [
        "# **Identificação das imagens duplicadas**\n",
        "Esta parte do código deve ser feita diretamente no desktop pois ao fazer diretamente no colab a sessão se desconecta por ser versão gratuita e não poder utilizar dos recursos por completa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULelk-7CBuzb"
      },
      "outputs": [],
      "source": [
        "# from pathlib import Path  # Para manipulação de caminhos de arquivos\n",
        "# import cv2                # OpenCV para processamento de imagem\n",
        "\n",
        "# # Define o diretório base como o atual\n",
        "# base_dir = Path.cwd()\n",
        "\n",
        "# # Define os caminhos de Treino e Teste\n",
        "# TRAIN_DIR = base_dir / \"Train\"\n",
        "# TEST_DIR = base_dir / \"Test\"\n",
        "\n",
        "# def compare_images(img1_path, img2_path, threshold=0.95):\n",
        "#     \"\"\"Compara duas imagens usando correlação de template.\"\"\"\n",
        "\n",
        "#     # Carrega imagens em escala de cinza\n",
        "#     img1 = cv2.imread(str(img1_path), cv2.IMREAD_GRAYSCALE)\n",
        "#     img2 = cv2.imread(str(img2_path), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "#     # Pula se o arquivo estiver corrompido ou não for encontrado\n",
        "#     if img1 is None or img2 is None:\n",
        "#         print(f\"Aviso: Não foi possível ler {img1_path} ou {img2_path}\")\n",
        "#         return False, 0.0\n",
        "\n",
        "#     # Redimensiona para um tamanho fixo\n",
        "#     img1 = cv2.resize(img1, (224, 224))\n",
        "#     img2 = cv2.resize(img2, (224, 224))\n",
        "\n",
        "#     # Calcula o coeficiente de correlação normalizado (valor de -1 a 1)\n",
        "#     correlation = cv2.matchTemplate(img1, img2, cv2.TM_CCOEFF_NORMED)[0,0]\n",
        "\n",
        "#     # Retorna True se a correlação for maior que o limiar\n",
        "#     return correlation > threshold, correlation\n",
        "\n",
        "# # Encontra todos os arquivos .jpg dentro das subpastas\n",
        "# train_paths = list(TRAIN_DIR.glob(\"*/*.jpg\"))\n",
        "# test_paths = list(TEST_DIR.glob(\"*/*.jpg\"))\n",
        "\n",
        "# # Imprime o status inicial\n",
        "# print(f\"Encontradas {len(train_paths)} imagens de treino.\")\n",
        "# print(f\"Encontradas {len(test_paths)} imagens de teste.\")\n",
        "# print(f\"Total de comparações a fazer: {len(train_paths) * len(test_paths)}\")\n",
        "# print(\"Iniciando varredura (isso pode levar muito tempo)...\")\n",
        "\n",
        "# # --- Loop Principal (Complexidade O(n*m) ---\n",
        "# duplicates_list = []  # Armazena os pares duplicados\n",
        "# counter = 0\n",
        "\n",
        "# # Itera sobre cada imagem de treino\n",
        "# for train_img in train_paths:\n",
        "#     # Compara com cada imagem de teste\n",
        "#     for test_img in test_paths:\n",
        "\n",
        "#         is_duplicate, correlation_score = compare_images(train_img, test_img)\n",
        "\n",
        "#         # Se forem similares o suficiente, registra\n",
        "#         if is_duplicate:\n",
        "#             counter += 1\n",
        "#             print(f\"Potencial duplicata #{counter}: {train_img.name} <-> {test_img.name} | Corr: {correlation_score:.4f}\")\n",
        "#             duplicates_list.append([str(train_img), str(test_img), correlation_score])\n",
        "\n",
        "# print(f\"\\nComparação concluída. Encontradas {counter} duplicatas em potencial.\")\n",
        "\n",
        "# # --- Geração do Relatório ---\n",
        "# output_file_path = base_dir / \"relatorio_duplicatas.txt\"\n",
        "\n",
        "# try:\n",
        "#     # Abre o arquivo de relatório (sobrescreve se existir)\n",
        "#     with open(output_file_path, 'w') as f:\n",
        "#         f.write(f\"Total de Duplicatas em Potencial Encontradas: {counter}\\n\")\n",
        "#         f.write(\"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "#         if not duplicates_list:\n",
        "#             f.write(\"Nenhuma duplicata encontrada.\\n\")\n",
        "#         else:\n",
        "#             # Escreve o cabeçalho da tabela\n",
        "#             f.write(f\"{'Correlação':<12} | {'Imagem de Treino':<50} | {'Imagem de Teste'}\\n\")\n",
        "#             f.write(\"-\" * 100 + \"\\n\")\n",
        "\n",
        "#             # Escreve cada duplicata encontrada no arquivo\n",
        "#             for item in duplicates_list:\n",
        "#                 train_path, test_path, score = item[0], item[1], item[2]\n",
        "#                 line = f\"{score:<12.4f} | {train_path:<50} | {test_path}\\n\"\n",
        "#                 f.write(line)\n",
        "\n",
        "#     print(f\"\\nRelatório de duplicatas salvo com sucesso em: {output_file_path}\")\n",
        "\n",
        "# except Exception as e:\n",
        "#     # Informa o usuário se houver erro ao salvar\n",
        "#     print(f\"\\nOcorreu um erro ao salvar o arquivo: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iErJShiVJO6T"
      },
      "source": [
        "# **Deletando as imagens duplicadas**\n",
        "Após obter o arquivo que contém as duplicatas é necessário apagar essas imagens. Para isso, foi feito o código abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntdmGqCARl8u",
        "outputId": "d5b1bcde-92ea-4740-af1e-81fedfc3c070"
      },
      "outputs": [],
      "source": [
        "import os, re, shutil, tempfile\n",
        "\n",
        "# ===================== CONFIGURE AQUI =====================\n",
        "# Raiz onde está o dataset ORIGINAL (pode ser somente-leitura, ex.: /kaggle/input/...)\n",
        "dataset_root = masoudnickparvar_brain_tumor_mri_dataset_path\n",
        "\n",
        "# Caminho do relatório .txt (pode estar em qualquer lugar)\n",
        "report_file = gabrielrocha2_duplicatas_path + \"/relatorio_duplicatas.txt\"  # <-- ajuste\n",
        "\n",
        "# Pasta espelho (gravável) para operar a limpeza\n",
        "writable_mirror = \"/content/clean_dataset\"\n",
        "\n",
        "# Por segurança, simulação primeiro\n",
        "DRY_RUN = False\n",
        "\n",
        "# (Opcional) fallback por prefixo Windows\n",
        "USE_PREFIX_FALLBACK = True\n",
        "WINDOWS_PREFIX = r\"C:\\Users\\LSE\\OneDrive\\Documentos\\Mestrado\\TrabalhoAP\"\n",
        "# ==========================================================\n",
        "\n",
        "# ---------- utilidades ----------\n",
        "def is_dir_writable(path_dir: str) -> bool:\n",
        "    try:\n",
        "        os.makedirs(path_dir, exist_ok=True)\n",
        "        fd, tmp = tempfile.mkstemp(dir=path_dir)\n",
        "        os.close(fd)\n",
        "        os.remove(tmp)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Regex para pegar sufixo a partir de Train/ ou Test/\n",
        "pat_tt = re.compile(r'[/\\\\](Train|Test)[/\\\\].*', flags=re.IGNORECASE)\n",
        "\n",
        "def to_dataset_relative(any_path: str) -> str | None:\n",
        "    \"\"\"Retorna 'Train/.../arquivo.jpg' ou 'Test/.../arquivo.jpg' a partir de um caminho Windows/Unix.\"\"\"\n",
        "    if not any_path:\n",
        "        return None\n",
        "    s = any_path.strip().strip('\"').strip(\"'\")\n",
        "    m = pat_tt.search(s)\n",
        "    if not m:\n",
        "        return None\n",
        "    rel = s[m.start()+1:].replace('\\\\', '/')\n",
        "    return rel\n",
        "\n",
        "def map_report_path(any_path: str, base_root: str) -> str | None:\n",
        "    \"\"\"Mapeia caminho do relatório para um arquivo dentro de base_root.\"\"\"\n",
        "    rel = to_dataset_relative(any_path)\n",
        "    if rel:\n",
        "        return os.path.join(base_root, rel)\n",
        "    if USE_PREFIX_FALLBACK:\n",
        "        s = any_path.strip().strip('\"').strip(\"'\").replace('\\\\', '/')\n",
        "        win_pref = WINDOWS_PREFIX.replace('\\\\', '/').lower()\n",
        "        if s.lower().startswith(win_pref):\n",
        "            rel2 = s[len(win_pref):].lstrip('/\\\\')\n",
        "            return os.path.join(base_root, rel2)\n",
        "    return None\n",
        "\n",
        "def is_noise_line(line: str) -> bool:\n",
        "    l = line.strip()\n",
        "    if not l: return True\n",
        "    if set(l) <= set(\"-=\"): return True\n",
        "    low = l.lower()\n",
        "    if low.startswith(\"total de duplicatas\") or low.startswith(\"correlação\"):\n",
        "        return True\n",
        "    if \"imagem de treino\" in low and \"imagem de teste\" in low:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# ---------- prepara espelho gravável se necessário ----------\n",
        "mirror_in_use = dataset_root\n",
        "# if not is_dir_writable(dataset_root):\n",
        "print(f\"[INFO] Diretório somente-leitura detectado: {dataset_root}\")\n",
        "print(f\"[INFO] Criando/atualizando espelho gravável em: {writable_mirror}\")\n",
        "# Copia o dataset inteiro uma única vez (se ainda não existir)\n",
        "if not os.path.exists(writable_mirror) or not os.listdir(writable_mirror):\n",
        "    shutil.copytree(dataset_root, writable_mirror, dirs_exist_ok=True)\n",
        "    print(\"[OK] Espelho criado/copied.\")\n",
        "else:\n",
        "    print(\"[OK] Espelho já existe — reutilizando.\")\n",
        "mirror_in_use = writable_mirror\n",
        "# else:\n",
        "#     print(f\"[OK] Diretório gravável: {dataset_root} — operando direto nele.\")\n",
        "\n",
        "# ---------- processamento do relatório ----------\n",
        "deleted_files_log = set()\n",
        "files_deleted_count = 0\n",
        "files_not_found_count = 0\n",
        "lines_processed = 0\n",
        "mapped_ok = 0\n",
        "mapped_fail = 0\n",
        "\n",
        "print(f\"Relatório: {report_file}\")\n",
        "print(f\"Operando em: {mirror_in_use}\")\n",
        "print(f\"DRY_RUN: {DRY_RUN}\")\n",
        "\n",
        "if not os.path.isfile(report_file):\n",
        "    raise FileNotFoundError(f\"Relatório não encontrado: {report_file}\")\n",
        "\n",
        "with open(report_file, 'r', encoding='latin-1') as f:\n",
        "    for raw in f:\n",
        "        lines_processed += 1\n",
        "        line = raw.rstrip('\\n')\n",
        "        if is_noise_line(line) or '|' not in line:\n",
        "            continue\n",
        "\n",
        "        parts = [p.strip() for p in line.split('|')]\n",
        "        if len(parts) != 3:\n",
        "            continue  # esperado: score | treino | teste\n",
        "\n",
        "        score_str, train_win, test_win = parts\n",
        "        if test_win.lower().startswith(\"imagem de teste\"):\n",
        "            continue\n",
        "\n",
        "        target_path = map_report_path(test_win, mirror_in_use)\n",
        "        if not target_path:\n",
        "            mapped_fail += 1\n",
        "            continue\n",
        "\n",
        "        mapped_ok += 1\n",
        "        if target_path in deleted_files_log:\n",
        "            continue\n",
        "        deleted_files_log.add(target_path)\n",
        "\n",
        "        if os.path.exists(target_path):\n",
        "            if DRY_RUN:\n",
        "                print(f\"[SIMULA EXCLUSÃO] {target_path}\")\n",
        "            else:\n",
        "                try:\n",
        "                    os.remove(target_path)\n",
        "                    print(f\"[EXCLUÍDO] {target_path}\")\n",
        "                    files_deleted_count += 1\n",
        "                except OSError as e:\n",
        "                    print(f\"[ERRO AO EXCLUIR] {target_path}: {e}\")\n",
        "        else:\n",
        "            print(f\"[NÃO ENCONTRADO] {target_path}\")\n",
        "            files_not_found_count += 1\n",
        "\n",
        "print(\"\\n--- Resumo ---\")\n",
        "print(f\"Linhas processadas: {lines_processed}\")\n",
        "print(f\"Mapeamentos OK: {mapped_ok}\")\n",
        "print(f\"Sem mapeamento: {mapped_fail}\")\n",
        "print(f\"Arquivos EXCLUÍDOS: {files_deleted_count}\")\n",
        "print(f\"Arquivos NÃO encontrados: {files_not_found_count}\")\n",
        "print(\"Quando estiver tudo certo, defina DRY_RUN = False para aplicar as exclusões.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMuPTxFD64hK",
        "outputId": "376ac3d4-2304-45d9-d811-35344f1866c1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# ===================== CONFIG BÁSICA (Colab) =====================\n",
        "# Informe aqui possíveis locais do seu dataset (adicione mais caminhos se quiser).\n",
        "CANDIDATE_BASE_DIRS = [\n",
        "    \"/content/clean_dataset\",\n",
        "    \"/content/dataset\",\n",
        "    \"/content/drive/MyDrive/clean_dataset\",  # se o Drive estiver montado\n",
        "]\n",
        "\n",
        "OUTPUT_DIR = \"/content/resplitted_dataset\"\n",
        "TRAIN_SPLIT_RATIO = 0.8\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# Detecta BASE_DIR existente\n",
        "BASE_DIR = None\n",
        "for c in CANDIDATE_BASE_DIRS:\n",
        "    if os.path.isdir(c):\n",
        "        BASE_DIR = Path(c)\n",
        "        break\n",
        "\n",
        "if BASE_DIR is None:\n",
        "    raise FileNotFoundError(\n",
        "        \"Não encontrei o dataset. Crie/copiei para um destes caminhos ou ajuste a lista:\\n\"\n",
        "        + \"\\n\".join(f\" - {p}\" for p in CANDIDATE_BASE_DIRS)\n",
        "    )\n",
        "\n",
        "print(f\"BASE_DIR: {BASE_DIR}\")\n",
        "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
        "\n",
        "# ===================== DETECÇÃO DE NOMES DAS PASTAS =====================\n",
        "# Aceita Train/Training (ou variações de caixa) e Test/Testing\n",
        "def pick_first_existing(parent, names):\n",
        "    for n in names:\n",
        "        p = os.path.join(parent, n)\n",
        "        if os.path.isdir(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "original_train_dir = pick_first_existing(BASE_DIR, [\"Train\", \"train\", \"Training\", \"training\"])\n",
        "original_test_dir  = pick_first_existing(BASE_DIR, [\"Test\", \"test\", \"Testing\", \"testing\"])\n",
        "\n",
        "if not original_train_dir and not original_test_dir:\n",
        "    raise FileNotFoundError(\n",
        "        f\"Não achei pastas de treino/teste em {BASE_DIR}.\\n\"\n",
        "        \"Esperado algo como 'Train'/'Training' e/ou 'Test'/'Testing' com subpastas de classes.\"\n",
        "    )\n",
        "\n",
        "print(\"Origem detectada:\")\n",
        "print(\"  Train dir:\", original_train_dir if original_train_dir else \"(ausente)\")\n",
        "print(\"  Test  dir:\", original_test_dir  if original_test_dir  else \"(ausente)\")\n",
        "\n",
        "# ===================== LISTA DE CLASSES =====================\n",
        "classes_in_train = set()\n",
        "classes_in_test  = set()\n",
        "\n",
        "if original_train_dir:\n",
        "    classes_in_train = {d.name for d in os.scandir(original_train_dir) if d.is_dir()}\n",
        "if original_test_dir:\n",
        "    classes_in_test  = {d.name for d in os.scandir(original_test_dir)  if d.is_dir()}\n",
        "\n",
        "all_classes = sorted(classes_in_train | classes_in_test)\n",
        "if not all_classes:\n",
        "    raise RuntimeError(\"Nenhuma subpasta de classe encontrada em Train/Training ou Test/Testing.\")\n",
        "\n",
        "print(\"Classes encontradas:\", all_classes)\n",
        "\n",
        "# ===================== CRIA SAÍDA =====================\n",
        "new_train_dir = os.path.join(OUTPUT_DIR, \"train\")\n",
        "new_test_dir  = os.path.join(OUTPUT_DIR, \"test\")\n",
        "os.makedirs(new_train_dir, exist_ok=True)\n",
        "os.makedirs(new_test_dir,  exist_ok=True)\n",
        "for cls in all_classes:\n",
        "    os.makedirs(os.path.join(new_train_dir, cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(new_test_dir,  cls), exist_ok=True)\n",
        "\n",
        "# ===================== FUNÇÕES ÚTEIS =====================\n",
        "def safe_copy(src, dst_dir):\n",
        "    \"\"\"Copia sem sobrescrever: se nome já existir, cria _1, _2, ...\"\"\"\n",
        "    base = os.path.basename(src)\n",
        "    name, ext = os.path.splitext(base)\n",
        "    dest = os.path.join(dst_dir, base)\n",
        "    k = 1\n",
        "    while os.path.exists(dest):\n",
        "        dest = os.path.join(dst_dir, f\"{name}_{k}{ext}\")\n",
        "        k += 1\n",
        "    shutil.copy2(src, dest)\n",
        "\n",
        "# ===================== SPLIT 80/20 =====================\n",
        "print(\"\\n--- Iniciando a separação 80/20 por classe ---\")\n",
        "total_train_all = 0\n",
        "total_test_all  = 0\n",
        "exts = ('*.jpg','*.jpeg','*.png','*.bmp','*.tif','*.tiff')\n",
        "\n",
        "for cls in all_classes:\n",
        "    print(f\"\\nProcessando classe: {cls}\")\n",
        "    imgs = []\n",
        "\n",
        "    if original_train_dir:\n",
        "        p_train = os.path.join(original_train_dir, cls)\n",
        "        if os.path.isdir(p_train):\n",
        "            for e in exts:\n",
        "                imgs.extend(glob.glob(os.path.join(p_train, e)))\n",
        "\n",
        "    if original_test_dir:\n",
        "        p_test = os.path.join(original_test_dir, cls)\n",
        "        if os.path.isdir(p_test):\n",
        "            for e in exts:\n",
        "                imgs.extend(glob.glob(os.path.join(p_test, e)))\n",
        "\n",
        "    # Remove duplicatas de caminho e embaralha\n",
        "    imgs = list(dict.fromkeys(imgs))\n",
        "    n = len(imgs)\n",
        "    if n == 0:\n",
        "        print(\"  Nenhuma imagem. Pulando.\")\n",
        "        continue\n",
        "\n",
        "    random.shuffle(imgs)\n",
        "    split_point = int(n * TRAIN_SPLIT_RATIO)\n",
        "    train_imgs = imgs[:split_point]\n",
        "    test_imgs  = imgs[split_point:]\n",
        "\n",
        "    print(f\"  Total: {n} | Treino: {len(train_imgs)} | Teste: {len(test_imgs)}\")\n",
        "\n",
        "    dt = os.path.join(new_train_dir, cls)\n",
        "    de = os.path.join(new_test_dir,  cls)\n",
        "\n",
        "    for p in train_imgs:\n",
        "        try:\n",
        "            safe_copy(p, dt)\n",
        "        except Exception as e:\n",
        "            print(f\"   [ERRO copiar treino] {p} -> {e}\")\n",
        "\n",
        "    for p in test_imgs:\n",
        "        try:\n",
        "            safe_copy(p, de)\n",
        "        except Exception as e:\n",
        "            print(f\"   [ERRO copiar teste]  {p} -> {e}\")\n",
        "\n",
        "    total_train_all += len(train_imgs)\n",
        "    total_test_all  += len(test_imgs)\n",
        "\n",
        "print(\"\\n--- Processo Concluído ---\")\n",
        "print(f\"Total de imagens de TREINO copiadas: {total_train_all}\")\n",
        "print(f\"Total de imagens de TESTE copiadas:  {total_test_all}\")\n",
        "print(f\"Total geral de imagens processadas: {total_train_all + total_test_all}\")\n",
        "print(f\"\\nSeus novos dados estão prontos em: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWGWMZqUxCmN"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# IMPORTAÇÕES E CONFIGURAÇÃO DO AMBIENTE\n",
        "# ----------------------------------------------------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import balanced_accuracy_score, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sWouzTl11sK"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# REPRODUTIBILIDADE\n",
        "# ----------------------------------------------------------------------\n",
        "SEED = 129\n",
        "\n",
        "def set_seeds(seed_value=SEED):\n",
        "    \"\"\"Fixa as sementes para reprodutibilidade.\"\"\"\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "set_seeds()\n",
        "\n",
        "# Montar o Google Drive\n",
        "# if not os.path.exists('/content/drive/MyDrive'):\n",
        "#     drive.mount('/content/drive')\n",
        "#     print(\"Google Drive montado.\")\n",
        "# else:\n",
        "#     print(\"Google Drive já está montado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgDt-ZqU18yt"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# DEFINIR CAMINHOS E PARÂMETROS\n",
        "# ----------------------------------------------------------------------\n",
        "base_dir = Path(\"/content/resplitted_dataset\")\n",
        "TRAIN_DIR = base_dir / \"train\"\n",
        "TEST_DIR = base_dir / \"test\"\n",
        "\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "N_CLASSES = 4\n",
        "IMG_SHAPE = IMG_SIZE + (3,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZQywhfpNUdl",
        "outputId": "28b03914-442c-4ce9-cee8-818ae1a30a69"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CARREGAR DADOS\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "print(\"Carregando dataset de treino e validação...\")\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    validation_split=0.2,    # 20% dos dados de treino irão para validação\n",
        "    subset=\"training\",\n",
        "    seed=SEED,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",     # Pegando a outra parte dos dados\n",
        "    seed=SEED,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "print(\"\\nCarregando dataset de teste...\")\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    TEST_DIR,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Verificação das classes\n",
        "class_names = train_dataset.class_names\n",
        "print(f\"\\nClasses encontradas: {class_names}\")\n",
        "print(f\"Número de classes: {len(class_names)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "rWZBoVh4tHvP",
        "outputId": "204a0da3-9363-460a-d23f-cdc09f894fe9"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# VISUALIZAR UM EXEMPLO DE CADA CLASSE\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "print(\"\\nExibindo um exemplo de cada classe...\")\n",
        "\n",
        "# Configura a grade de plotagem (1 linha, 4 colunas)\n",
        "plt.figure(figsize=(16, 4))\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    ax = plt.subplot(1, N_CLASSES, i + 1)\n",
        "\n",
        "    # 1. Encontra o caminho para a subpasta da classe\n",
        "    class_dir = TRAIN_DIR / class_name\n",
        "\n",
        "    try:\n",
        "        # 2. Pega o nome do PRIMEIRO arquivo de imagem nessa pasta\n",
        "        sample_image_name = os.listdir(class_dir)[0]\n",
        "\n",
        "        # 3. Monta o caminho completo para essa imagem\n",
        "        sample_image_path = class_dir / sample_image_name\n",
        "\n",
        "        # 4. Carrega a imagem\n",
        "        img = tf.keras.utils.load_img(\n",
        "            sample_image_path,\n",
        "            target_size=IMG_SIZE\n",
        "        )\n",
        "\n",
        "        # 5. Mostra a imagem\n",
        "        plt.imshow(img)\n",
        "        plt.title(class_name)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Se a pasta estiver vazia ou der um erro\n",
        "        plt.title(f\"{class_name}\\n(Erro ao carregar)\")\n",
        "        plt.axis(\"off\")\n",
        "        print(f\"Erro ao carregar imagem da classe {class_name}: {e}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Salvando caminhos dos arquivos de teste...\")\n",
        "test_filepaths = test_dataset.file_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG_bXAxNNaWw"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# OTIMIZAR O CARREGAMENTO (PERFORMANCE)\n",
        "# ----------------------------------------------------------------------\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHfR23kENe2d",
        "outputId": "79f9cd7d-69da-4284-9ec3-bcda3c01af04"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CRIAR CAMADA DE \"DATA AUGMENTATION\"\n",
        "# ----------------------------------------------------------------------\n",
        "data_augmentation = Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\", input_shape=IMG_SHAPE),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ],\n",
        "    name=\"data_augmentation\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHNUzxTyNi4E"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CONSTRUINDO O MODELO CNN\n",
        "# ----------------------------------------------------------------------\n",
        "model = Sequential([\n",
        "    # 1. Camada de \"Aumento de Dados\"\n",
        "    data_augmentation,\n",
        "\n",
        "    # 2. Normalização: Mapeia pixels de [0, 255] para [0, 1]\n",
        "    layers.Rescaling(1./255),\n",
        "\n",
        "    # 3. Bloco Convolucional 1\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    # 4. Bloco Convolucional 2\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    # 5. Bloco Convolucional 3\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    # 6. Bloco Convolucional 4\n",
        "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    # 7. Camada de \"Dropout\"\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # 8. Achatar (Flatten)\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # 9. Camada Densa\n",
        "    layers.Dense(256, activation='relu'),\n",
        "\n",
        "    # 10. Camada de Saída\n",
        "    layers.Dense(N_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5iQJLmKytds"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CALLBACK: REGISTRAR TEMPO POR ÉPOCA\n",
        "# ----------------------------------------------------------------------\n",
        "class TimeHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.epoch_times = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        self.epoch_times.append(epoch_time)\n",
        "        print(f\" - Tempo da Época: {epoch_time:.2f}s\")\n",
        "\n",
        "time_callback = TimeHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "iSTUOfLFNrPf",
        "outputId": "4ec0b529-5874-4c08-e6ca-d4f228cb861b"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# COMPILANDO O MODELO\n",
        "# ----------------------------------------------------------------------\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='roc_auc')]\n",
        ")\n",
        "\n",
        "# Callback para parar o treino se a performance não melhorar\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', # Monitorar a perda na validação\n",
        "    patience=10,        # Parar após 10 épocas sem melhora\n",
        "    verbose=1,\n",
        "    restore_best_weights=True # Salvar o melhor modelo\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5My5JKVFNvsq",
        "outputId": "77d1ea1e-b039-44a9-c784-e00878aa38f2"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# TREINANDO O MODELO\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "print(\"\\nIniciando o treinamento...\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping, time_callback]\n",
        ")\n",
        "\n",
        "print(\"Treinamento concluído.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psDeTtJuNzxX",
        "outputId": "c5c434a4-bb1d-4087-b32a-bce3b27ec165"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# AVALIAÇÃO DO MODELO COM DADOS DE TESTE\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "print(\"\\nIniciando avaliação no dataset de TESTE...\")\n",
        "loss, accuracy, roc_auc = model.evaluate(test_dataset)\n",
        "\n",
        "print(f\"\\n--- Resultados da Avaliação de Teste ---\")\n",
        "print(f\"Perda (Loss) no Teste: {loss:.4f}\")\n",
        "print(f\"Acurácia no Teste: {accuracy * 100:.2f}%\")\n",
        "print(f\"ROC-AUC no Teste: {roc_auc:.4f}\")\n",
        "\n",
        "print(\"\\n--- Custo Computacional ---\")\n",
        "tempos_por_epoca = time_callback.epoch_times\n",
        "print(f\"Hardware: (Executando no Google Colab)\")\n",
        "print(f\"Tempo médio por época: {np.mean(tempos_por_epoca):.2f}s\")\n",
        "print(f\"Tempo total de treino: {np.sum(tempos_por_epoca):.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "6jVYjKe2N3JC",
        "outputId": "29985a4c-786b-4e11-ba4a-3744b5460720"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# PLOTAR OS RESULTADOS DO TREINAMENTO\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Gráfico de Acurácia\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Acurácia (Treino)')\n",
        "plt.plot(epochs_range, val_acc, label='Acurácia (Validação)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Acurácia de Treino vs. Validação')\n",
        "\n",
        "# Gráfico de Perda (Loss)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Perda (Treino)')\n",
        "plt.plot(epochs_range, val_loss, label='Perda (Validação)')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Perda de Treino vs. Validação')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "TLwHRe6UcPoE",
        "outputId": "65ea4e7d-cf01-465b-8e70-00d8459412d6"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# MATRIZ DE CONFUSÃO\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "print(\"\\nGerando Matriz de Confusão para o Set de TESTE...\")\n",
        "\n",
        "# Obter as previsões\n",
        "y_pred_probs = model.predict(test_dataset)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1) # Converter probabilidades para classes\n",
        "\n",
        "# Obter as classes reais do test_dataset\n",
        "y_true_classes = []\n",
        "for images, labels in test_dataset:\n",
        "    y_true_classes.extend(np.argmax(labels.numpy(), axis=1))\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Plotar a matriz de confusão\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.ylabel('Classe Real')\n",
        "plt.title('Matriz de Confusão do Set de TESTE')\n",
        "plt.show()\n",
        "\n",
        "# Imprimir o relatório de classificação completo (F1-score, Precision, Recall)\n",
        "print(\"\\nRelatório de Classificação (Set de TESTE):\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "nRnRdst9yWdD",
        "outputId": "eab392cd-eb27-44c4-c9c9-434ce3108eba"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# MÉTRICAS: BALANCED ACCURACY E CURVAS ROC\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 1. Balanced Accuracy\n",
        "bal_acc = balanced_accuracy_score(y_true_classes, y_pred_classes)\n",
        "print(f\"Acurácia Balanceada (Balanced Accuracy): {bal_acc:.4f}\")\n",
        "\n",
        "# --- 2. Curvas ROC e ROC-AUC (One-vs-Rest) ---\n",
        "\n",
        "# Binarizar os rótulos reais (y_true)\n",
        "y_true_binarized = label_binarize(y_true_classes, classes=range(N_CLASSES))\n",
        "\n",
        "# Dicionários para guardar os valores de FPR, TPR e AUC\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "# Calcular FPR, TPR e AUC para cada classe\n",
        "for i in range(N_CLASSES):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_probs[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plotar as curvas ROC\n",
        "plt.figure(figsize=(10, 8))\n",
        "colors = ['blue', 'red', 'green', 'orange']\n",
        "for i, color in zip(range(N_CLASSES), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label=f'Classe {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2) # Linha de chance aleatória\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
        "plt.title('Curvas ROC Multi-Classe (One-vs-Rest)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5slJY2NuzH4Y",
        "outputId": "aba54dc8-cd8e-4a08-f960-358dc8ce7536"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# ANÁLISE DE ERRO (AMOSTRAS COMENTADAS)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Pegar todos os caminhos de arquivo do set de teste\n",
        "#test_filepaths = test_dataset.file_paths\n",
        "\n",
        "# Encontrar os índices dos erros\n",
        "errors = np.where(y_pred_classes != y_true_classes)[0]\n",
        "print(f\"\\nTotal de erros no set de teste: {len(errors)} de {len(y_true_classes)} amostras.\")\n",
        "\n",
        "if len(errors) > 0:\n",
        "    print(\"Exibindo as primeiras 9 amostras classificadas incorretamente...\")\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for i, error_index in enumerate(errors[:9]):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "\n",
        "        # Carregar a imagem original\n",
        "        img = tf.keras.utils.load_img(test_filepaths[error_index], target_size=IMG_SIZE)\n",
        "        plt.imshow(img)\n",
        "\n",
        "        real_label = class_names[y_true_classes[error_index]]\n",
        "        pred_label = class_names[y_pred_classes[error_index]]\n",
        "\n",
        "        plt.title(f\"Real: {real_label}\\nPredito: {pred_label}\", color='red')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"O modelo acertou todas as amostras do set de teste!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRAjvbi1AaQO"
      },
      "source": [
        "# **==============================================================================================================**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sUlzafyAleD"
      },
      "source": [
        "# **=======================================YOLO=======================================**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOpMXUEdAjCX"
      },
      "source": [
        "# **==============================================================================================================**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Dz4XogAQJ0"
      },
      "source": [
        "# **INSTALAÇÃO DE LIBS E DE EXTENSÕES** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuR7jLVNBr3s",
        "outputId": "8543a820-a456-44c0-833c-dab81e81491e"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "masoudnickparvar_brain_tumor_mri_dataset_path = kagglehub.dataset_download('masoudnickparvar/brain-tumor-mri-dataset')\n",
        "ahmedsorour1_mri_for_brain_tumor_with_bounding_boxes_path = kagglehub.dataset_download('ahmedsorour1/mri-for-brain-tumor-with-bounding-boxes')\n",
        "gabrielrocha2_duplicatas_path = kagglehub.dataset_download('gabrielrocha2/duplicatas')\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSx5MnXhAQJ0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Limpar o trio para evitar sobras binárias\n",
        "# !pip uninstall -y numpy scipy scikit-learn\n",
        "\n",
        "# # Instalar um conjunto compatível e moderno\n",
        "# !pip install --no-cache-dir --force-reinstall \\\n",
        "#   \"numpy==2.0.2\" \"scipy==1.13.1\" \"scikit-learn==1.5.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T17:19:28.498495Z",
          "iopub.status.busy": "2025-11-09T17:19:28.497974Z",
          "iopub.status.idle": "2025-11-09T17:19:29.383874Z",
          "shell.execute_reply": "2025-11-09T17:19:29.383284Z",
          "shell.execute_reply.started": "2025-11-09T17:19:28.498461Z"
        },
        "id": "NN48OhvCAQJ0",
        "outputId": "ceb7bc6a-31d0-446d-b4c3-0fea8d1f385e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy, scipy, sklearn\n",
        "from scipy._lib import _util\n",
        "print(\"NumPy:\", numpy.__version__, \"| SciPy:\", scipy.__version__, \"| Sklearn:\", sklearn.__version__)\n",
        "print(\"has np_vecdot?\", hasattr(_util, \"np_vecdot\"))  # deve ser True\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(\"✅ sklearn OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYxvv_Q-AQJ1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install --no-cache-dir --force-reinstall \"scipy==1.13.1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-09T17:21:39.337172Z",
          "iopub.status.busy": "2025-11-09T17:21:39.336676Z",
          "iopub.status.idle": "2025-11-09T17:21:48.31857Z",
          "shell.execute_reply": "2025-11-09T17:21:48.317703Z",
          "shell.execute_reply.started": "2025-11-09T17:21:39.337131Z"
        },
        "id": "Ecp_tfWnAQJ1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y numpy scipy scikit-learn ml_dtypes tensorflow tensorflow-text tensorflow-decision-forests tf-keras mkl-umath mkl-random mkl-fft numba ydata-profiling\n",
        "#!pip install --no-cache-dir --force-reinstall \"numpy==1.26.4\" \"scipy==1.10.1\" \"scikit-learn==1.3.2\"\n",
        "#!pip install -U ultralytics opencv-python matplotlib\n",
        "# !pip install -U ultralytics opencv-python scikit-learn matplotlib\n",
        "import os, shutil, json, glob, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "from ultralytics import YOLO  # supports yolo11 and yolo8 models\n",
        "\n",
        "# All necessary imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import ipywidgets as widgets\n",
        "import io\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQScb_uIAQJ1"
      },
      "source": [
        "# **CONFIGURAÇÕES DO AMBIENTE** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T17:26:06.96721Z",
          "iopub.status.busy": "2025-11-09T17:26:06.966395Z",
          "iopub.status.idle": "2025-11-09T17:26:07.100876Z",
          "shell.execute_reply": "2025-11-09T17:26:07.100206Z",
          "shell.execute_reply.started": "2025-11-09T17:26:06.967185Z"
        },
        "id": "8JKHAdxsAQJ1",
        "outputId": "0af23e37-ea7e-4376-a8be-fcb1534b85e0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import platform\n",
        "import torch\n",
        "import psutil\n",
        "\n",
        "print(\"=== CONFIGURAÇÃO DE AMBIENTE ===\")\n",
        "print(f\"Sistema Operacional: {platform.platform()}\")\n",
        "print(f\"Python: {platform.python_version()}\")\n",
        "print(f\"CPU: {platform.processor()} ({psutil.cpu_count(logical=True)} núcleos)\")\n",
        "print(f\"Memória RAM: {round(psutil.virtual_memory().total / 1e9, 2)} GB\")\n",
        "print()\n",
        "\n",
        "# PyTorch\n",
        "print(\"PyTorch versão:\", torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA disponível ✅\")\n",
        "    print(\"GPU ativa:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Total de GPUs:\", torch.cuda.device_count())\n",
        "    print(\"Versão CUDA:\", torch.version.cuda)\n",
        "else:\n",
        "    print(\"CUDA não detectada ❌\")\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\nDispositivo em uso: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LzHY_fRAQJ1"
      },
      "source": [
        "# **UNIÃO DE TODAS AS IMAGENS E LABELS EM UM SÓ DIRETÓRIO PARA REALIZAR O SPLIT CORRETAMENTE** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T17:26:19.578236Z",
          "iopub.status.busy": "2025-11-09T17:26:19.577931Z",
          "iopub.status.idle": "2025-11-09T17:28:20.889452Z",
          "shell.execute_reply": "2025-11-09T17:28:20.88873Z",
          "shell.execute_reply.started": "2025-11-09T17:26:19.57821Z"
        },
        "id": "H03I0iPbAQJ1",
        "outputId": "84429e23-e51c-457b-c48a-431f4ae3028a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# === CONFIGURAÇÕES ===\n",
        "# Caminho do dataset original (mude conforme o seu dataset Kaggle)\n",
        "# Exemplo: \"/kaggle/input/brain-tumor-dataset\"\n",
        "# BASE_DIR = \"/kaggle/input/mri-for-brain-tumor-with-bounding-boxes\"\n",
        "BASE_DIR = ahmedsorour1_mri_for_brain_tumor_with_bounding_boxes_path\n",
        "\n",
        "# Caminho onde será criada a nova estrutura YOLO\n",
        "# OUTPUT_DIR = \"/kaggle/working/mri_brain_dataset_yolo_unified\"\n",
        "OUTPUT_DIR = \"/content/mri_brain_dataset_yolo_unified\"\n",
        "\n",
        "# Cria as novas pastas únicas para imagens e labels\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"labels\"), exist_ok=True)\n",
        "\n",
        "# Pastas de origem (train e val originais)\n",
        "SOURCE_SETS = [\"Train\", \"Val\"]\n",
        "\n",
        "# === COPIA E RENOMEIA OS ARQUIVOS ===\n",
        "for source_split in SOURCE_SETS:\n",
        "    split_path = os.path.join(BASE_DIR, source_split)\n",
        "\n",
        "    for class_name in os.listdir(split_path):\n",
        "        class_path = os.path.join(split_path, class_name)\n",
        "        images_path = os.path.join(class_path, \"images\")\n",
        "        labels_path = os.path.join(class_path, \"labels\")\n",
        "\n",
        "        if not os.path.isdir(images_path) or not os.path.isdir(labels_path):\n",
        "            continue\n",
        "\n",
        "        # Copia as imagens\n",
        "        for img_file in os.listdir(images_path):\n",
        "            src = os.path.join(images_path, img_file)\n",
        "            dst = os.path.join(OUTPUT_DIR, \"images\", f\"{class_name}_{img_file}\")\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "        # Copia os labels\n",
        "        for label_file in os.listdir(labels_path):\n",
        "            src = os.path.join(labels_path, label_file)\n",
        "            dst = os.path.join(OUTPUT_DIR, \"labels\", f\"{class_name}_{label_file}\")\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "print(\"✅ Dataset convertido e unificado com sucesso!\")\n",
        "print(\"Nova estrutura criada em:\", OUTPUT_DIR)\n",
        "print()\n",
        "print(\"dataset_yolo/\")\n",
        "print(\" ├─ images/\")\n",
        "print(\" └─ labels/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pp5I_8uAQJ1"
      },
      "source": [
        "# **APAGANDO DUPLICATAS PARA NÃO ENVIESAR O MODELO** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T17:28:20.8912Z",
          "iopub.status.busy": "2025-11-09T17:28:20.890961Z",
          "iopub.status.idle": "2025-11-09T17:28:26.325361Z",
          "shell.execute_reply": "2025-11-09T17:28:26.324621Z",
          "shell.execute_reply.started": "2025-11-09T17:28:20.891172Z"
        },
        "id": "fqQH-hThAQJ1",
        "outputId": "927e588e-ca6f-4f73-fc47-36f1b0fb3888",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os, re, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# ===== CONFIG =====\n",
        "# DATASET_ROOT = Path(\"/kaggle/working/mri_brain_dataset_yolo_unified\")      # dataset unificado\n",
        "DATASET_ROOT = Path(OUTPUT_DIR)\n",
        "IMAGES_DIR   = DATASET_ROOT / \"images\"\n",
        "LABELS_DIR   = DATASET_ROOT / \"labels\"\n",
        "\n",
        "# DUPES_FILE   = Path(\"/kaggle/input/duplicatas/relatorio_duplicatas.txt\")\n",
        "DUPES_FILE   = Path(gabrielrocha2_duplicatas_path + \"/relatorio_duplicatas.txt\")\n",
        "CORR_MIN     = 0.5 # coloquei treshold mas todos os relatados no txt realmente são duplicados (correlação maior de 95%)\n",
        "DRY_RUN      = False # se DRY_RUN false apaga no dataset, se true apenas printa os duplicados\n",
        "QUARANTINE   = None # se quiser isolar passar o path para o diretorio\n",
        "\n",
        "\n",
        "# ===== HELPERS =====\n",
        "def basename_win(path_str: str) -> str:\n",
        "    \"\"\"Extrai o basename de um path Windows/Unix (\\ ou /).\"\"\"\n",
        "    return re.split(r\"[\\\\/]+\", path_str.strip())[-1]\n",
        "\n",
        "def parse_dupe_lines(text: str):\n",
        "    \"\"\"Lê linhas 'corr | caminhoA | caminhoB' → [{'corr':float,'a':str,'b':str}, ...].\"\"\"\n",
        "    items = []\n",
        "    for ln in text.splitlines():\n",
        "        t = ln.strip()\n",
        "        if not t or t.startswith(\"Total de\") or set(t) in ({'='}, {'-'}):\n",
        "            continue\n",
        "        parts = [p.strip() for p in t.split(\"|\")]\n",
        "        if len(parts) != 3:\n",
        "            continue\n",
        "        try:\n",
        "            corr = float(parts[0].replace(\",\", \".\"))\n",
        "        except ValueError:\n",
        "            continue\n",
        "        items.append({\"corr\": corr, \"a\": parts[1], \"b\": parts[2]})\n",
        "    return items\n",
        "\n",
        "def build_image_index(images_dir: Path):\n",
        "    \"\"\"Cria índice {basename_lower: Path} e uma lista completa p/ fallback por sufixo.\"\"\"\n",
        "    index = {}\n",
        "    all_paths = []\n",
        "    # pega somente arquivos na pasta images (sem recursão, já que a estrutura está plana)\n",
        "    for p in images_dir.iterdir():\n",
        "        if p.is_file() and p.suffix.lower() in {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"}:\n",
        "            index[p.name.lower()] = p\n",
        "            all_paths.append(p)\n",
        "    return index, all_paths\n",
        "\n",
        "def find_image_by_basename(basename: str, idx: dict, all_paths: list[Path]) -> Path | None:\n",
        "    \"\"\"1) match exato (case-insensitive); 2) fallback: termina com esse basename (caso tenha prefixo).\"\"\"\n",
        "    key = basename.lower()\n",
        "    if key in idx:\n",
        "        return idx[key]\n",
        "    for p in all_paths:\n",
        "        if p.name.lower().endswith(key):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def label_for_image(img_path: Path) -> Path:\n",
        "    return LABELS_DIR / f\"{img_path.stem}.txt\"\n",
        "\n",
        "def delete_pair(img_path: Path):\n",
        "    lbl = label_for_image(img_path)\n",
        "    if DRY_RUN:\n",
        "        print(f\"[DRY] DEL IMG: {img_path}\")\n",
        "        print(f\"[DRY] DEL LBL: {lbl} {'(não existe)' if not lbl.exists() else ''}\")\n",
        "        return\n",
        "    if QUARANTINE:\n",
        "        q_img = QUARANTINE / \"images\" / img_path.name\n",
        "        q_lbl = QUARANTINE / \"labels\" / lbl.name\n",
        "        q_img.parent.mkdir(parents=True, exist_ok=True)\n",
        "        q_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.move(str(img_path), str(q_img))\n",
        "        if lbl.exists(): shutil.move(str(lbl), str(q_lbl))\n",
        "        print(f\"[MOVE] {img_path.name} -> quarentena\")\n",
        "        return\n",
        "    img_path.unlink(missing_ok=True)\n",
        "    if lbl.exists(): lbl.unlink()\n",
        "    print(f\"[OK] Removido: {img_path.name}\")\n",
        "\n",
        "# ===== SANITY CHECK =====\n",
        "assert IMAGES_DIR.exists(), f\"Não encontrado {IMAGES_DIR}\"\n",
        "assert LABELS_DIR.exists(), f\"Não encontrado {LABELS_DIR}\"\n",
        "assert DUPES_FILE.exists(), f\"Não encontrado na lista: {DUPES_FILE}\"\n",
        "\n",
        "print(\"IMAGES_DIR:\", IMAGES_DIR)\n",
        "print(\"LABELS_DIR:\", LABELS_DIR)\n",
        "\n",
        "img_index, img_all = build_image_index(IMAGES_DIR)\n",
        "print(f\"Imagens indexadas: {len(img_index)}\")\n",
        "print(\"Exemplos:\", [p.name for p in img_all[:5]])\n",
        "\n",
        "# ===== PROCESSAMENTO =====\n",
        "items = parse_dupe_lines(DUPES_FILE.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
        "eligible = [r for r in items if r[\"corr\"] >= CORR_MIN]\n",
        "print(f\"Duplicatas elegíveis (corr >= {CORR_MIN}): {len(eligible)}\")\n",
        "\n",
        "deleted = 0\n",
        "not_found = 0\n",
        "\n",
        "for rec in eligible:\n",
        "    a_base = basename_win(rec[\"a\"])\n",
        "    b_base = basename_win(rec[\"b\"])\n",
        "\n",
        "    a_img = find_image_by_basename(a_base, img_index, img_all)\n",
        "    b_img = find_image_by_basename(b_base, img_index, img_all)\n",
        "\n",
        "    # regra simples: se os dois existem, apaga o B; se só um existe, apaga o que existe\n",
        "    target = b_img or a_img\n",
        "    if target is None:\n",
        "        not_found += 1\n",
        "        print(f\"[MISS] Não encontrados: {a_base} | {b_base}\")\n",
        "        continue\n",
        "\n",
        "    delete_pair(target)\n",
        "    deleted += 1\n",
        "\n",
        "print(\"\\n===== RESUMO =====\")\n",
        "print(f\"Apagadas (ou DRY): {deleted}\")\n",
        "print(f\"Não localizadas: {not_found}\")\n",
        "print(\"Modo:\", \"DRY-RUN (sem apagar)\" if DRY_RUN else (\"QUARENTENA\" if QUARANTINE else \"APAGANDO\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T17:28:26.326502Z",
          "iopub.status.busy": "2025-11-09T17:28:26.326223Z",
          "iopub.status.idle": "2025-11-09T17:28:26.643929Z",
          "shell.execute_reply": "2025-11-09T17:28:26.643221Z",
          "shell.execute_reply.started": "2025-11-09T17:28:26.326477Z"
        },
        "id": "xAzEBLy9AQJ2",
        "outputId": "0634393d-1c06-4e87-f285-afaf96c9baa8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ===== Consistência YOLO + remoção de órfãos e itens com issues =====\n",
        "import os, csv, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# === CONFIGS ===\n",
        "#DATASET_ROOT = Path(\"/kaggle/working/dataset_yolo\")  # contém images/ e labels/\n",
        "IMAGES_DIR   = DATASET_ROOT / \"images\"\n",
        "LABELS_DIR   = DATASET_ROOT / \"labels\"\n",
        "\n",
        "IMAGE_EXTS   = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "CLASSES      = [\"glioma\",\"meningioma\",\"no_tumor\",\"pituitary\"] # erro na ordem das classes, refazer\n",
        "\n",
        "# Ações (escolha)\n",
        "DRY_RUN               = False   # primeiro rodando em True para revisar\n",
        "DELETE_ORPHAN_LABELS  = True  # apaga labels sem imagem\n",
        "DELETE_ORPHAN_IMAGES  = True  # apaga imagens sem label\n",
        "DELETE_ISSUE_ITEMS    = True   # apaga imagem + label quando houver issue no label\n",
        "QUARANTINE            = None   # ex.: Path(\"/kaggle/working/_quarentena\") para mover ao invés de apagar\n",
        "\n",
        "# Saídas\n",
        "# OUT_DIR = Path(\"/kaggle/working/yolo_checks\")\n",
        "OUT_DIR = Path(\"/content/yolo_checks\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "REPORT_CSV          = OUT_DIR / \"dataset_yolo_report.csv\"\n",
        "ORPHAN_IMAGES_TXT   = OUT_DIR / \"images_sem_label.txt\"\n",
        "ORPHAN_LABELS_TXT   = OUT_DIR / \"labels_sem_imagem.txt\"\n",
        "ISSUE_STEMS_TXT     = OUT_DIR / \"stems_com_issues.txt\"\n",
        "\n",
        "# === Sanity ===\n",
        "assert IMAGES_DIR.exists(), f\"Não encontrado {IMAGES_DIR}\"\n",
        "assert LABELS_DIR.exists(), f\"Não encontrado {LABELS_DIR}\"\n",
        "\n",
        "# === Indexação (por stem) ===\n",
        "def list_images(images_dir: Path):\n",
        "    return {p.stem: p for p in images_dir.iterdir()\n",
        "            if p.is_file() and p.suffix.lower() in IMAGE_EXTS}\n",
        "\n",
        "def list_labels(labels_dir: Path):\n",
        "    return {p.stem: p for p in labels_dir.iterdir()\n",
        "            if p.is_file() and p.suffix.lower() == \".txt\"}\n",
        "\n",
        "img_idx = list_images(IMAGES_DIR)\n",
        "lbl_idx = list_labels(LABELS_DIR)\n",
        "\n",
        "imgs_set = set(img_idx.keys())\n",
        "lbls_set = set(lbl_idx.keys())\n",
        "\n",
        "# === Órfãos ===\n",
        "images_without_label = sorted(imgs_set - lbls_set)\n",
        "labels_without_image = sorted(lbls_set - imgs_set)\n",
        "\n",
        "# === Validação de conteúdo YOLO ===\n",
        "def parse_line(line):\n",
        "    # formato: class cx cy w h [ignora resto]\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) < 5:\n",
        "        return {\"ok\": False, \"err\": \"colunas<5\"}\n",
        "    try:\n",
        "        cls = int(float(parts[0]))\n",
        "        cx, cy, w, h = map(float, parts[1:5])\n",
        "    except Exception:\n",
        "        return {\"ok\": False, \"err\": \"parse_float/int\"}\n",
        "\n",
        "    if not (0 <= cls < len(CLASSES)):\n",
        "        return {\"ok\": False, \"err\": f\"class_out_of_range:{cls}\"}\n",
        "    for v in (cx, cy, w, h):\n",
        "        if not (0.0 <= v <= 1.0):\n",
        "            return {\"ok\": False, \"err\": \"coords_out_of_[0,1]\"}\n",
        "    if w <= 0 or h <= 0:\n",
        "        return {\"ok\": False, \"err\": \"w/h<=0\"}\n",
        "    return {\"ok\": True}\n",
        "\n",
        "issues = []            # linhas para CSV\n",
        "issue_stems = set()    # stems com algum problema\n",
        "\n",
        "for stem in sorted(imgs_set & lbls_set):\n",
        "    lbl_path = lbl_idx[stem]\n",
        "    text = lbl_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    lines = [ln for ln in text.splitlines() if ln.strip()]\n",
        "\n",
        "    if len(lines) == 0:\n",
        "        issues.append({\"stem\": stem, \"type\": \"label_empty\", \"detail\": \"arquivo .txt vazio\"})\n",
        "        issue_stems.add(stem)\n",
        "        continue\n",
        "\n",
        "    for i, ln in enumerate(lines, start=1):\n",
        "        res = parse_line(ln)\n",
        "        if not res[\"ok\"]:\n",
        "            issues.append({\"stem\": stem, \"type\": \"label_invalid\", \"detail\": f\"linha {i}: {res['err']}\"})\n",
        "            issue_stems.add(stem)\n",
        "\n",
        "# === Helpers de mover/apagar ===\n",
        "def do_remove(p: Path, subdir: str):\n",
        "    if DRY_RUN:\n",
        "        print(f\"[DRY] remover: {p}\")\n",
        "        return\n",
        "    if QUARANTINE:\n",
        "        dst = QUARANTINE / subdir / p.name\n",
        "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.move(str(p), str(dst))\n",
        "        print(f\"[MOVE] {p} -> {dst}\")\n",
        "    else:\n",
        "        p.unlink(missing_ok=True)\n",
        "        print(f\"[DEL] {p}\")\n",
        "\n",
        "def remove_image_and_label(stem: str):\n",
        "    img = img_idx.get(stem)\n",
        "    lbl = lbl_idx.get(stem)\n",
        "    if img is None and lbl is None:\n",
        "        print(f\"[SKIP] {stem}: nem imagem nem label presentes.\")\n",
        "        return\n",
        "    if img is not None:\n",
        "        do_remove(img, \"images\")\n",
        "        # após remover, também retire do índice para evitar dupla ação\n",
        "        img_idx.pop(stem, None)\n",
        "    if lbl is not None:\n",
        "        do_remove(lbl, \"labels\")\n",
        "        lbl_idx.pop(stem, None)\n",
        "\n",
        "# === Ações: órfãos ===\n",
        "if DELETE_ORPHAN_LABELS:\n",
        "    for stem in labels_without_image:\n",
        "        do_remove(lbl_idx[stem], \"labels\")\n",
        "\n",
        "if DELETE_ORPHAN_IMAGES:\n",
        "    for stem in images_without_label:\n",
        "        do_remove(img_idx[stem], \"images\")\n",
        "\n",
        "# === Ações: itens com issues (remove imagem + label) ===\n",
        "if DELETE_ISSUE_ITEMS and issue_stems:\n",
        "    print(f\"\\n=== Removendo itens com issues (total: {len(issue_stems)}) ===\")\n",
        "    for stem in sorted(issue_stems):\n",
        "        remove_image_and_label(stem)\n",
        "\n",
        "# === Relatórios ===\n",
        "# CSV de issues\n",
        "with REPORT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=[\"stem\",\"type\",\"detail\"])\n",
        "    w.writeheader()\n",
        "    for row in issues:\n",
        "        w.writerow(row)\n",
        "\n",
        "# Listas de órfãos e issues\n",
        "ORPHAN_IMAGES_TXT.write_text(\"\\n\".join(images_without_label), encoding=\"utf-8\")\n",
        "ORPHAN_LABELS_TXT.write_text(\"\\n\".join(labels_without_image), encoding=\"utf-8\")\n",
        "ISSUE_STEMS_TXT.write_text(\"\\n\".join(sorted(issue_stems)), encoding=\"utf-8\")\n",
        "\n",
        "# === Resumo ===\n",
        "print(\"\\n===== RESUMO =====\")\n",
        "print(f\"Imagens totais: {len(list_images(IMAGES_DIR))} (após remoções em memória)\")\n",
        "print(f\"Labels  totais: {len(list_labels(LABELS_DIR))} (após remoções em memória)\")\n",
        "print(f\"Imagens SEM label: {len(images_without_label)}  -> {ORPHAN_IMAGES_TXT}\")\n",
        "print(f\"Labels  SEM imagem: {len(labels_without_image)}  -> {ORPHAN_LABELS_TXT}\")\n",
        "print(f\"Stems com issues: {len(issue_stems)}           -> {ISSUE_STEMS_TXT}\")\n",
        "print(f\"Relatório detalhado: {REPORT_CSV}\")\n",
        "print(\"Modo:\", \"DRY-RUN (sem apagar/mover)\" if DRY_RUN else (\"QUARENTENA\" if QUARANTINE else \"APAGANDO\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HdChKtRAQJ2"
      },
      "source": [
        "# **SPLIT CONFIGURÁVEL FEITO PARA TRAIN VAL E TEST, NO FORMATO EM QUE O YOLO ESPERA** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T17:28:26.644874Z",
          "iopub.status.busy": "2025-11-09T17:28:26.64467Z",
          "iopub.status.idle": "2025-11-09T17:28:27.798575Z",
          "shell.execute_reply": "2025-11-09T17:28:27.797889Z",
          "shell.execute_reply.started": "2025-11-09T17:28:26.644858Z"
        },
        "id": "7WPxAQ_SAQJ2",
        "outputId": "8dab5190-d747-4332-d4c5-6ced175fb197",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# === CONFIGURAÇÕES ===\n",
        "# DATASET_DIR = \"/kaggle/working/mri_brain_dataset_yolo_unified\"  # caminho do dataset unificado\n",
        "DATASET_DIR = DATASET_ROOT\n",
        "# OUTPUT_DIR = \"/kaggle/working/mri_brain_dataset_yolo_split\"  # onde será criado o split final\n",
        "OUTPUT_DIR = \"/content/mri_brain_dataset_yolo_split\"\n",
        "\n",
        "# Proporções do split (soma deve ser 1.0)\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.2\n",
        "TEST_RATIO = 0.1\n",
        "\n",
        "# Cria pastas de destino no formato YOLO\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, \"images\", split), exist_ok=True)\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, \"labels\", split), exist_ok=True)\n",
        "\n",
        "# Lista todas as imagens disponíveis\n",
        "all_images = [f for f in os.listdir(os.path.join(DATASET_DIR, \"images\")) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "all_images.sort()\n",
        "\n",
        "# Embaralha para aleatoriedade\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Calcula índices de divisão\n",
        "n_total = len(all_images)\n",
        "n_train = int(n_total * TRAIN_RATIO)\n",
        "n_val = int(n_total * VAL_RATIO)\n",
        "n_test = n_total - n_train - n_val\n",
        "\n",
        "train_files = all_images[:n_train]\n",
        "val_files = all_images[n_train:n_train + n_val]\n",
        "test_files = all_images[n_train + n_val:]\n",
        "\n",
        "# Função para copiar arquivos de imagem e label\n",
        "def copy_split(files, split_name):\n",
        "    for img_file in files:\n",
        "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
        "        img_src = os.path.join(DATASET_DIR, \"images\", img_file)\n",
        "        lbl_src = os.path.join(DATASET_DIR, \"labels\", label_file)\n",
        "\n",
        "        img_dst = os.path.join(OUTPUT_DIR, \"images\", split_name, img_file)\n",
        "        lbl_dst = os.path.join(OUTPUT_DIR, \"labels\", split_name, label_file)\n",
        "\n",
        "        # Copia imagem\n",
        "        shutil.copy2(img_src, img_dst)\n",
        "\n",
        "        # Copia label (se existir)\n",
        "        if os.path.exists(lbl_src):\n",
        "            shutil.copy2(lbl_src, lbl_dst)\n",
        "\n",
        "# Copia os arquivos\n",
        "copy_split(train_files, \"train\")\n",
        "copy_split(val_files, \"val\")\n",
        "copy_split(test_files, \"test\")\n",
        "\n",
        "print(\"✅ Split concluído com sucesso!\")\n",
        "print(f\"Total de imagens: {n_total}\")\n",
        "print(f\" - Treino: {len(train_files)}\")\n",
        "print(f\" - Validação: {len(val_files)}\")\n",
        "print(f\" - Teste: {len(test_files)}\")\n",
        "print()\n",
        "print(\"Estrutura criada em:\", OUTPUT_DIR)\n",
        "print(\"\"\"\n",
        "dataset_split/\n",
        "├─ images/\n",
        "│   ├─ train/\n",
        "│   ├─ val/\n",
        "│   └─ test/\n",
        "└─ labels/\n",
        "    ├─ train/\n",
        "    ├─ val/\n",
        "    └─ test/\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZeiJIyvAQJ2"
      },
      "source": [
        "# **INCLUSÃO DE PARAMETROS E DIRETÓRIOS** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-09T17:28:27.800628Z",
          "iopub.status.busy": "2025-11-09T17:28:27.800182Z",
          "iopub.status.idle": "2025-11-09T17:28:27.80514Z",
          "shell.execute_reply": "2025-11-09T17:28:27.804504Z",
          "shell.execute_reply.started": "2025-11-09T17:28:27.800607Z"
        },
        "id": "qqj8_e14AQJ2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==== PROJECT ROOTS ====\n",
        "ROOT = \"/content\"\n",
        "PROJECT_DIR = Path(ROOT) / \"brain_tumor_pipeline\"\n",
        "PROJECT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# TODO: point these to your extracted datasets (Kaggle/Figshare/Harvard Medical)\n",
        "# Expecting a YOLO-style detection dataset for step 4 (images + labels in YOLO txt format).\n",
        "# DETECTION_DATA_ROOT = Path('/kaggle/working/mri_brain_dataset_yolo_split' )  # e.g., .../BrainTumorYolo\n",
        "DETECTION_DATA_ROOT = Path(OUTPUT_DIR)\n",
        "#  ├─ images/\n",
        "#  │    ├─ train/*.jpg (or .png)\n",
        "#  │    ├─ val/*.jpg\n",
        "#  │    └─ test/*.jpg\n",
        "#  └─ labels/\n",
        "#       ├─ train/*.txt\n",
        "#       ├─ val/*.txt\n",
        "#       └─ test/*.txt\n",
        "# YOLO txt: class cx cy w h (normalized)\n",
        "\n",
        "# Class names (index order must match the YOLO labels)\n",
        "#CLASSES = [\"glioma\", \"meningioma\", \"pituitary\", \"no_tumor\"]\n",
        "\n",
        "# ==== MODEL / TRAINING PARAMS ====\n",
        "IMG_SIZE_CNN = (150, 150)     # (Resize, Preprocess)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_CNN = 25\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "CONF_THRES = 0.25   # detection confidence threshold\n",
        "IOU_THRES = 0.5     # NMS threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdxCXa4rAQJ2"
      },
      "source": [
        "# **SALVA CONFIGURAÇÃO DO YOLO** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T17:28:27.806101Z",
          "iopub.status.busy": "2025-11-09T17:28:27.805898Z",
          "iopub.status.idle": "2025-11-09T17:28:27.828345Z",
          "shell.execute_reply": "2025-11-09T17:28:27.827619Z",
          "shell.execute_reply.started": "2025-11-09T17:28:27.806084Z"
        },
        "id": "pJ3kv6DIAQJ2",
        "outputId": "082e8de7-c39f-4881-acc2-c3eae758c0d5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def write_yolo_yaml(root, yaml_path, class_names):\n",
        "    # garante que 'root' e 'yaml_path' sejam Path mesmo que venham como string\n",
        "    root = Path(root)\n",
        "    yaml_path = Path(yaml_path)\n",
        "\n",
        "    text = f\"\"\"path: {root.resolve()}\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "names:\n",
        "\"\"\"\n",
        "    for i, name in enumerate(class_names):\n",
        "        text += f\"  {i}: {name}\\n\"\n",
        "\n",
        "    yaml_path.write_text(text)\n",
        "    print(f\"[YOLO] YAML gerado em: {yaml_path}\")\n",
        "\n",
        "YOLO_DATA_YAML = PROJECT_DIR/\"brain_tumor_yolo.yaml\"\n",
        "write_yolo_yaml(OUTPUT_DIR, YOLO_DATA_YAML, CLASSES)\n",
        "print(YOLO_DATA_YAML.read_text())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kayarx5UAQJ3"
      },
      "source": [
        "# **TREINAMENTO DO MODELO** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T17:28:27.829251Z",
          "iopub.status.busy": "2025-11-09T17:28:27.829033Z",
          "iopub.status.idle": "2025-11-09T18:03:14.3203Z",
          "shell.execute_reply": "2025-11-09T18:03:14.31956Z",
          "shell.execute_reply.started": "2025-11-09T17:28:27.829224Z"
        },
        "id": "EyCe84eMAQJ3",
        "outputId": "ea15519c-f09f-4096-9b47-c5865b39f676",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Train YOLO detector\n",
        "yolo = YOLO(\"yolo11n.pt\") #testar com modelo de classificação\n",
        "results = yolo.train(\n",
        "    data=str(YOLO_DATA_YAML),\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    optimizer=\"Adam\",\n",
        "    lr0=1e-3,\n",
        "    weight_decay=5e-4,\n",
        "    patience=10,\n",
        "    device=0 if DEVICE==\"cuda\" else \"cpu\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEmOkYsXAQJ3"
      },
      "source": [
        "# **SALVA MELHORES RESULTADOS DO MODELO** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-09T18:03:14.322179Z",
          "iopub.status.busy": "2025-11-09T18:03:14.321629Z",
          "iopub.status.idle": "2025-11-09T18:03:14.327171Z",
          "shell.execute_reply": "2025-11-09T18:03:14.326474Z",
          "shell.execute_reply.started": "2025-11-09T18:03:14.322137Z"
        },
        "id": "ME1tK_TaAQJ3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Best weights path (Ultralytics saves to runs/detect/train*/weights/best.pt)\n",
        "best_weights = Path(yolo.trainer.best) if hasattr(yolo, \"trainer\") else None\n",
        "if best_weights is None or not best_weights.exists():\n",
        "    # try default save path format\n",
        "    candidates = list(Path(\"runs/detect\").glob(\"*/weights/best.pt\"))\n",
        "    best_weights = candidates[-1] if candidates else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUQ5bPldAQJ3"
      },
      "source": [
        "# **UTILIZA MELHORES RESULTADOS** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:03:14.328449Z",
          "iopub.status.busy": "2025-11-09T18:03:14.327965Z",
          "iopub.status.idle": "2025-11-09T18:03:14.389988Z",
          "shell.execute_reply": "2025-11-09T18:03:14.389317Z",
          "shell.execute_reply.started": "2025-11-09T18:03:14.328422Z"
        },
        "id": "_chIaoxmAQJ3",
        "outputId": "1bbfb22a-4d48-4ff8-fc8a-4c5f3a85794e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "assert best_weights is not None and best_weights.exists(), \"Could not locate trained YOLO weights.\"\n",
        "print(f\"[YOLO] Using weights: {best_weights}\")\n",
        "detector = YOLO(str(best_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WFeJC4NAQJ3"
      },
      "source": [
        "# **VISUALIZAÇÃO DOS GRÁFICOS E INFORMAÇÕES QUE O PROPRIO YOLO GERA COMO HISTORICO** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:04:50.177971Z",
          "iopub.status.busy": "2025-11-09T18:04:50.177422Z",
          "iopub.status.idle": "2025-11-09T18:04:57.943259Z",
          "shell.execute_reply": "2025-11-09T18:04:57.942318Z",
          "shell.execute_reply.started": "2025-11-09T18:04:50.177943Z"
        },
        "id": "8QqJO4PpAQJ3",
        "outputId": "2e292a46-d316-40fa-c20c-bd3b9df5f77f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Gera/regera as métricas de detecção (inclui mAP, PR/F1/P/R e confusion_matrix.png)\n",
        "val_res = detector.val(data=\"/content/brain_tumor_pipeline/brain_tumor_yolo.yaml\", split=\"test\", imgsz=640, conf=0.25, iou=0.5, plots=True, verbose=False)\n",
        "print(val_res.results_dict)  # mAP50, mAP50-95, precision, recall etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:04:57.945833Z",
          "iopub.status.busy": "2025-11-09T18:04:57.945077Z",
          "iopub.status.idle": "2025-11-09T18:04:57.98895Z",
          "shell.execute_reply": "2025-11-09T18:04:57.98838Z",
          "shell.execute_reply.started": "2025-11-09T18:04:57.945809Z"
        },
        "id": "ah1tuspPAQJ3",
        "outputId": "eaa50871-bccc-4c9f-e3c6-befca4ce9cb3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from IPython.display import display, Image\n",
        "\n",
        "runs_root = Path(\"/content/runs/detect\")\n",
        "cands = sorted(runs_root.glob(\"val*\"), key=lambda p: p.stat().st_mtime) or \\\n",
        "        sorted(runs_root.glob(\"train*\"), key=lambda p: p.stat().st_mtime)\n",
        "assert cands, \"Nenhum run encontrado em runs/detect/\"\n",
        "run = cands[-1]\n",
        "print(\"Run selecionado:\", run)\n",
        "\n",
        "imgs = [\n",
        "    run/\"results.png\",           # curvas de treino/val (loss, mAP)\n",
        "    run/\"F1_curve.png\",\n",
        "    run/\"PR_curve.png\",\n",
        "    run/\"P_curve.png\",\n",
        "    run/\"R_curve.png\",\n",
        "    run/\"confusion_matrix.png\",  # matriz de confusão (detecção)\n",
        "    run/\"labels.jpg\",\n",
        "    run/\"val_batch0_pred.jpg\",\n",
        "    run/\"val_batch1_pred.jpg\",\n",
        "    run/\"val_batch2_pred.jpg\",\n",
        "]\n",
        "for p in imgs:\n",
        "    if p.exists():\n",
        "        print(p.name)\n",
        "        display(Image(filename=str(p)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg9H6Z5XAQJ3"
      },
      "source": [
        "# **TESTA E GERA OS PARAMETROS DE AVALIAÇÃO, BEM COMO A MATRIZ DE CONFUSÃO** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:04:57.989823Z",
          "iopub.status.busy": "2025-11-09T18:04:57.989624Z",
          "iopub.status.idle": "2025-11-09T18:05:04.824806Z",
          "shell.execute_reply": "2025-11-09T18:05:04.824007Z",
          "shell.execute_reply.started": "2025-11-09T18:04:57.989807Z"
        },
        "id": "eqkzy1C0AQJ3",
        "outputId": "2ee547d8-5790-407d-e3db-338186af642e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from sklearn.metrics import f1_score, balanced_accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "import json\n",
        "\n",
        "ID_NO_TUMOR = CLASSES.index(\"no_tumor\")\n",
        "\n",
        "def read_yolo_label(txt_path: Path):\n",
        "    if not txt_path.exists(): return []\n",
        "    out = []\n",
        "    for ln in txt_path.read_text().splitlines():\n",
        "        p = ln.split()\n",
        "        if len(p) < 5: continue\n",
        "        c = int(float(p[0])); cx,cy,w,h = map(float, p[1:5])\n",
        "        out.append((c,cx,cy,w,h))\n",
        "    return out\n",
        "\n",
        "def img_true_class(img_path: Path):\n",
        "    lab = Path(OUTPUT_DIR)/\"labels\"/\"test\"/(img_path.stem + \".txt\")\n",
        "    boxes = read_yolo_label(lab)\n",
        "    if not boxes: return ID_NO_TUMOR\n",
        "    # maior área normalizada\n",
        "    areas = [b[3]*b[4] for b in boxes]\n",
        "    return boxes[int(np.argmax(areas))][0]\n",
        "\n",
        "test_images = sorted(list((Path(OUTPUT_DIR)/\"images\"/\"test\").glob(\"*.jpg\")) + list((Path(OUTPUT_DIR)/\"images\"/\"test\").glob(\"*.png\")))\n",
        "y_true, y_pred, y_prob = [], [], []\n",
        "\n",
        "for img_path in test_images:\n",
        "    # GT por imagem\n",
        "    y_true.append(img_true_class(img_path))\n",
        "\n",
        "    # Predição\n",
        "    pred_list = detector.predict(source=str(img_path), conf=0.25, iou=0.5, verbose=False)\n",
        "    res = pred_list[0]\n",
        "    if res is None or res.boxes is None or len(res.boxes)==0:\n",
        "        y_pred.append(ID_NO_TUMOR)\n",
        "        prob = np.zeros(len(CLASSES), dtype=float); prob[ID_NO_TUMOR] = 1.0\n",
        "        y_prob.append(prob)\n",
        "        continue\n",
        "\n",
        "    # pega detecção com MAIOR SCORE\n",
        "    scores = res.boxes.conf.cpu().numpy()\n",
        "    cls_ids = res.boxes.cls.cpu().numpy().astype(int)\n",
        "    k = int(np.argmax(scores))\n",
        "    cls_hat = int(cls_ids[k]); score_hat = float(scores[k])\n",
        "    y_pred.append(cls_hat)\n",
        "\n",
        "    # vetor de probabilidades “soft” (coloca score na classe vencedora)\n",
        "    prob = np.zeros(len(CLASSES), dtype=float)\n",
        "    prob[cls_hat] = score_hat\n",
        "    # opcional: normalizar, mas não é necessário para métricas top-1\n",
        "    y_prob.append(prob)\n",
        "\n",
        "y_true = np.array(y_true); y_pred = np.array(y_pred); y_prob = np.vstack(y_prob)\n",
        "\n",
        "# Métricas de classificação (imagem)\n",
        "f1m  = f1_score(y_true, y_pred, average=\"macro\")\n",
        "bal  = balanced_accuracy_score(y_true, y_pred)\n",
        "try:\n",
        "    roc  = roc_auc_score(np.eye(len(CLASSES))[y_true], y_prob, multi_class=\"ovr\", average=\"macro\")\n",
        "except Exception:\n",
        "    roc  = np.nan\n",
        "\n",
        "print(f\"[YOLO→Classificação] F1 macro={f1m:.4f} | Balanced Acc={bal:.4f} | ROC-AUC={roc:.4f}\")\n",
        "print(classification_report(y_true, y_pred, target_names=CLASSES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:06:31.620979Z",
          "iopub.status.busy": "2025-11-09T18:06:31.62065Z",
          "iopub.status.idle": "2025-11-09T18:06:32.158234Z",
          "shell.execute_reply": "2025-11-09T18:06:32.157552Z",
          "shell.execute_reply.started": "2025-11-09T18:06:31.620956Z"
        },
        "id": "3ddutcWgAQJ3",
        "outputId": "01614d90-489b-456c-ce06-8a1667871be4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    f1_score, balanced_accuracy_score, roc_auc_score,\n",
        "    classification_report, confusion_matrix,\n",
        "    roc_curve, auc, precision_recall_curve\n",
        ")\n",
        "# ROC/PR (macro) por imagem\n",
        "Y = np.eye(len(CLASSES))[y_true]\n",
        "\n",
        "# ROC macro\n",
        "fpr, tpr = {}, {}\n",
        "for i in range(len(CLASSES)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(Y[:, i], y_prob[:, i])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(CLASSES))]))\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(len(CLASSES)):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "mean_tpr /= len(CLASSES)\n",
        "macro_roc_auc = auc(all_fpr, mean_tpr)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(all_fpr, mean_tpr, lw=2, label=f\"Macro ROC (AUC={macro_roc_auc:.3f})\")\n",
        "plt.plot([0,1],[0,1],'--',lw=1)\n",
        "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (macro)\"); plt.legend()\n",
        "plt.tight_layout(); plt.savefig(\"roc_macro.png\", dpi=150); plt.show()\n",
        "\n",
        "# PR macro\n",
        "prec, rec = [], []\n",
        "grid = np.linspace(0,1,500)\n",
        "for i in range(len(CLASSES)):\n",
        "    pi, ri, _ = precision_recall_curve(Y[:, i], y_prob[:, i])\n",
        "    # garantir eixo x crescente\n",
        "    prec.append(np.interp(grid, ri[::-1], pi[::-1]))\n",
        "macro_prec = np.mean(np.vstack(prec), axis=0)\n",
        "macro_pr_auc = auc(grid, macro_prec)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(grid, macro_prec, lw=2, label=f\"Macro PR (AUC={macro_pr_auc:.3f})\")\n",
        "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall (macro)\"); plt.legend()\n",
        "plt.tight_layout(); plt.savefig(\"pr_macro.png\", dpi=150); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:06:32.159851Z",
          "iopub.status.busy": "2025-11-09T18:06:32.159584Z",
          "iopub.status.idle": "2025-11-09T18:06:36.87623Z",
          "shell.execute_reply": "2025-11-09T18:06:36.875532Z",
          "shell.execute_reply.started": "2025-11-09T18:06:32.159833Z"
        },
        "id": "P7hFtR-HAQJ4",
        "outputId": "a39dbfba-10fa-487a-8ec9-bfef75cb19b1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def bootstrap_cis(y_true, y_pred, y_prob, n_classes, n_boot=1000, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    N = len(y_true)\n",
        "    f1m, bal, roc = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.integers(0, N, N)\n",
        "        yt = y_true[idx]; yp = y_pred[idx]; pr = y_prob[idx]\n",
        "        f1m.append(f1_score(yt, yp, average=\"macro\"))\n",
        "        bal.append(balanced_accuracy_score(yt, yp))\n",
        "        try:\n",
        "            roc_auc = roc_auc_score(np.eye(n_classes)[yt], pr, multi_class=\"ovr\", average=\"macro\")\n",
        "        except Exception:\n",
        "            roc_auc = np.nan\n",
        "        roc.append(roc_auc)\n",
        "    def ci(a):\n",
        "        a = np.array(a, dtype=float)\n",
        "        a = a[~np.isnan(a)]\n",
        "        return np.nanmean(a), np.nanpercentile(a, 2.5), np.nanpercentile(a, 97.5)\n",
        "    return ci(f1m), ci(bal), ci(roc)\n",
        "\n",
        "(f1m_mean, f1m_lo, f1m_hi), (bal_mean, bal_lo, bal_hi), (roc_mean, roc_lo, roc_hi) = bootstrap_cis(\n",
        "    y_true, y_pred, y_prob, n_classes=len(CLASSES), n_boot=1000, seed=123\n",
        ")\n",
        "\n",
        "print(f\"F1 macro: {f1m_mean:.4f}  (95% CI: {f1m_lo:.4f}–{f1m_hi:.4f})\")\n",
        "print(f\"Balanced Acc: {bal_mean:.4f}  (95% CI: {bal_lo:.4f}–{bal_hi:.4f})\")\n",
        "print(f\"ROC-AUC macro: {roc_mean:.4f}  (95% CI: {roc_lo:.4f}–{roc_hi:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:06:36.877181Z",
          "iopub.status.busy": "2025-11-09T18:06:36.876933Z",
          "iopub.status.idle": "2025-11-09T18:06:37.174048Z",
          "shell.execute_reply": "2025-11-09T18:06:37.173072Z",
          "shell.execute_reply.started": "2025-11-09T18:06:36.87714Z"
        },
        "id": "YWO0jkllAQJ4",
        "outputId": "74dbfbee-cd90-4eec-800e-11be99a566b2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(CLASSES))))\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion Matrix (image-level)')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(CLASSES))\n",
        "plt.xticks(tick_marks, CLASSES, rotation=45, ha='right')\n",
        "plt.yticks(tick_marks, CLASSES)\n",
        "plt.xlabel('Predicted'); plt.ylabel('True'); plt.tight_layout()\n",
        "plt.savefig(\"confusion_matrix_image_level.png\", dpi=150); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksQNCXV7AQJ4"
      },
      "source": [
        "# **GERAÇÃO DAS IMAGENS DE TESTE COM O \"GROUND TRUTH\" E O PREDITO PELO MODELO PARA COMPARAÇÃO** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:06:37.175776Z",
          "iopub.status.busy": "2025-11-09T18:06:37.175567Z",
          "iopub.status.idle": "2025-11-09T18:15:22.719804Z",
          "shell.execute_reply": "2025-11-09T18:15:22.718995Z",
          "shell.execute_reply.started": "2025-11-09T18:06:37.175761Z"
        },
        "id": "aNrR3AMSAQJ4",
        "outputId": "bc7321ef-8f2d-445d-f5f0-4111c407056c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==== VISUALIZAÇÃO YOLO: GT vs PRED (TP/FP/FN) ====\n",
        "#!pip -q install -U ultralytics\n",
        "\n",
        "import os, csv, math, numpy as np\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ===== CONFIG =====\n",
        "#CLASSES = [\"glioma\",\"meningioma\",\"no_tumor\",\"pituitary\"] #deixar comentado pois o classes ja foi instanciado no inicio\n",
        "\n",
        "# aponte para o split desejado (ex.: test)\n",
        "DATA_ROOT   = Path(OUTPUT_DIR)   # onde tem images/test e labels/test\n",
        "SPLIT       = \"test\"                                             # \"train\" | \"val\" | \"test\"\n",
        "IMAGES_DIR  = DATA_ROOT / \"images\" / SPLIT\n",
        "LABELS_DIR  = DATA_ROOT / \"labels\" / SPLIT\n",
        "\n",
        "WEIGHTS     = Path(\"/content/runs/detect/train/weights/best.pt\")  # ajuste para o seu best.pt\n",
        "OUT_DIR     = Path(\"/content/vis_yolo\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CONF_THRES  = 0.25\n",
        "IOU_THRES   = 0.5\n",
        "MAX_IMAGES  = None        # opcional: exibir só N imagens (None = todas)\n",
        "\n",
        "# ===== UTILS =====\n",
        "def read_gt_xyxy(txt_path: Path, w: int, h: int):\n",
        "    \"\"\"Lê YOLO txt (class cx cy w h) -> listas boxes(xyxy) e labels.\"\"\"\n",
        "    boxes, labels = [], []\n",
        "    if not txt_path.exists():\n",
        "        return boxes, labels\n",
        "    for ln in txt_path.read_text().splitlines():\n",
        "        p = ln.strip().split()\n",
        "        if len(p) < 5: continue\n",
        "        c, cx, cy, bw, bh = int(float(p[0])), *map(float, p[1:5])\n",
        "        x1 = (cx - bw/2.0) * w; y1 = (cy - bh/2.0) * h\n",
        "        x2 = (cx + bw/2.0) * w; y2 = (cy + bh/2.0) * h\n",
        "        boxes.append([x1,y1,x2,y2]); labels.append(c)\n",
        "    return boxes, labels\n",
        "\n",
        "def iou_xyxy(a, b):\n",
        "    ax1, ay1, ax2, ay2 = a\n",
        "    bx1, by1, bx2, by2 = b\n",
        "    inter_x1 = max(ax1, bx1); inter_y1 = max(ay1, by1)\n",
        "    inter_x2 = min(ax2, bx2); inter_y2 = min(ay2, by2)\n",
        "    iw = max(0.0, inter_x2 - inter_x1); ih = max(0.0, inter_y2 - inter_y1)\n",
        "    inter = iw * ih\n",
        "    area_a = max(0.0, (ax2-ax1)) * max(0.0, (ay2-ay1))\n",
        "    area_b = max(0.0, (bx2-bx1)) * max(0.0, (by2-by1))\n",
        "    union = area_a + area_b - inter + 1e-9\n",
        "    return inter / union\n",
        "\n",
        "def match_predictions(gt_boxes, gt_labels, pr_boxes, pr_labels, pr_scores, iou_th=0.5):\n",
        "    \"\"\"\n",
        "    Matching guloso por score.\n",
        "    Retorna: tps (idxs de preds), fp (idxs de preds), fn (idxs de gts), ious (IoU dos TPs).\n",
        "    \"\"\"\n",
        "    # Converte tudo que vamos indexar/ordenar para numpy (evita -list e garante slicing por idxs)\n",
        "    pr_scores_np = np.asarray(pr_scores, dtype=float)\n",
        "    pr_labels_np = np.asarray(pr_labels, dtype=int)\n",
        "    pr_boxes_np  = np.asarray(pr_boxes, dtype=float)  # shape: (N,4) ou (0,)\n",
        "\n",
        "    if pr_scores_np.size == 0:\n",
        "        return [], [], list(range(len(gt_boxes))), []\n",
        "\n",
        "    # ordenar por score decrescente\n",
        "    order = np.argsort(-pr_scores_np)\n",
        "\n",
        "    used_gt = set()\n",
        "    tps, fp, ious = [], [], []\n",
        "\n",
        "    for i in order:\n",
        "        best_j, best_iou = -1, 0.0\n",
        "        # tenta casar só com GTs da MESMA classe e ainda não usados\n",
        "        for j, (gbox, glab) in enumerate(zip(gt_boxes, gt_labels)):\n",
        "            if j in used_gt:\n",
        "                continue\n",
        "            if int(pr_labels_np[i]) != int(glab):\n",
        "                continue\n",
        "            iou = iou_xyxy(pr_boxes_np[i], gbox)\n",
        "            if iou > best_iou:\n",
        "                best_iou, best_j = iou, j\n",
        "\n",
        "        if best_iou >= iou_th and best_j >= 0:\n",
        "            used_gt.add(best_j)\n",
        "            tps.append(int(i))\n",
        "            ious.append(float(best_iou))\n",
        "        else:\n",
        "            fp.append(int(i))\n",
        "\n",
        "    fn = [j for j in range(len(gt_boxes)) if j not in used_gt]\n",
        "    return tps, fp, fn, ious\n",
        "\n",
        "def draw_box(ax, box, color, label=None):\n",
        "    x1,y1,x2,y2 = box\n",
        "    ax.add_patch(plt.Rectangle((x1,y1), x2-x1, y2-y1, fill=False, linewidth=2, edgecolor=color))\n",
        "    if label:\n",
        "        ax.text(x1, max(0,y1-3), label, fontsize=9, color=\"white\",\n",
        "                bbox=dict(facecolor=color, edgecolor=color, pad=1.5, alpha=0.7))\n",
        "\n",
        "def visualize(img_bgr, gt_boxes, gt_labels, pr_boxes, pr_labels, pr_scores, tps, fp, fn, save_prefix):\n",
        "    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    h,w = img.shape[:2]\n",
        "\n",
        "    # Overlay combinado\n",
        "    fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "    ax.imshow(img); ax.axis(\"off\")\n",
        "    # GT (verde)\n",
        "    for j in range(len(gt_boxes)):\n",
        "        color = \"lime\"\n",
        "        lab = f\"GT:{CLASSES[gt_labels[j]]}\"\n",
        "        draw_box(ax, gt_boxes[j], color, lab)\n",
        "    # TP (azul)\n",
        "    for i in tps:\n",
        "        lab = f\"TP:{CLASSES[pr_labels[i]]} {pr_scores[i]:.2f}\"\n",
        "        draw_box(ax, pr_boxes[i], \"dodgerblue\", lab)\n",
        "    # FP (vermelho)\n",
        "    for i in fp:\n",
        "        lab = f\"FP:{CLASSES[pr_labels[i]]} {pr_scores[i]:.2f}\"\n",
        "        draw_box(ax, pr_boxes[i], \"red\", lab)\n",
        "    # FN (amarelo) -> caixas GT não cobertas\n",
        "    for j in fn:\n",
        "        lab = f\"FN:{CLASSES[gt_labels[j]]}\"\n",
        "        draw_box(ax, gt_boxes[j], \"yellow\", lab)\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f\"{save_prefix}_overlay.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Lado-a-lado: esquerda GT, direita Pred\n",
        "    fig, axes = plt.subplots(1,2,figsize=(14,7))\n",
        "    for k in range(2):\n",
        "        axes[k].imshow(img); axes[k].axis(\"off\")\n",
        "    # GT\n",
        "    for j in range(len(gt_boxes)):\n",
        "        draw_box(axes[0], gt_boxes[j], \"lime\", f\"GT:{CLASSES[gt_labels[j]]}\")\n",
        "    axes[0].set_title(\"Ground Truth\")\n",
        "    # Preds (colorindo TP/FP)\n",
        "    for i in tps:\n",
        "        draw_box(axes[1], pr_boxes[i], \"dodgerblue\", f\"TP:{CLASSES[pr_labels[i]]} {pr_scores[i]:.2f}\")\n",
        "    for i in fp:\n",
        "        draw_box(axes[1], pr_boxes[i], \"red\", f\"FP:{CLASSES[pr_labels[i]]} {pr_scores[i]:.2f}\")\n",
        "    axes[1].set_title(\"Predições YOLO\")\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f\"{save_prefix}_sidebyside.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# ===== LOAD MODEL =====\n",
        "assert IMAGES_DIR.exists() and LABELS_DIR.exists(), \"Diretórios de imagens/labels não encontrados.\"\n",
        "assert WEIGHTS.exists(), f\"Pesos não encontrados: {WEIGHTS}\"\n",
        "#model = YOLO(str(WEIGHTS))\n",
        "model = detector\n",
        "# ===== RUN & SAVE =====\n",
        "image_paths = sorted([p for p in IMAGES_DIR.iterdir() if p.suffix.lower() in {\".jpg\",\".jpeg\",\".png\"}])\n",
        "if MAX_IMAGES is not None:\n",
        "    image_paths = image_paths[:MAX_IMAGES]\n",
        "\n",
        "summary_csv = OUT_DIR / f\"summary_{SPLIT}.csv\"\n",
        "with summary_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"image\",\"tp\",\"fp\",\"fn\",\"mean_iou_TP\",\"pred_major(label,score)\",\"gt_major(label)\"])\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = cv2.imread(str(img_path))\n",
        "        height, width = img.shape[:2]   # ← renomeei aqui\n",
        "\n",
        "        # GT\n",
        "        gt_boxes, gt_labels = read_gt_xyxy(LABELS_DIR / (img_path.stem + \".txt\"), width, height)\n",
        "\n",
        "        # Pred\n",
        "        res = model.predict(source=str(img_path), conf=CONF_THRES, iou=IOU_THRES, verbose=False)[0]\n",
        "        if res is None or res.boxes is None or len(res.boxes)==0:\n",
        "            pr_boxes, pr_labels, pr_scores = [], [], []\n",
        "        else:\n",
        "            pr_boxes  = res.boxes.xyxy.cpu().numpy()\n",
        "            pr_labels = res.boxes.cls.cpu().numpy().astype(int)\n",
        "            pr_scores = res.boxes.conf.cpu().numpy().astype(float)\n",
        "\n",
        "        # Matching\n",
        "        tps, fps, fns, ious = match_predictions(gt_boxes, gt_labels, pr_boxes, pr_labels, pr_scores, IOU_THRES)\n",
        "\n",
        "        # Visual\n",
        "        save_prefix = str(OUT_DIR / img_path.stem)\n",
        "        visualize(img, gt_boxes, gt_labels, pr_boxes, pr_labels, pr_scores, tps, fps, fns, save_prefix)\n",
        "\n",
        "        # resumo por imagem\n",
        "        if len(pr_scores):\n",
        "            k = int(np.argmax(pr_scores))\n",
        "            pred_major = f\"{CLASSES[pr_labels[k]]},{pr_scores[k]:.3f}\"\n",
        "        else:\n",
        "            pred_major = \"no_pred,0.000\"\n",
        "        gt_major = CLASSES[gt_labels[np.argmax([b[2]-b[0] for b in gt_boxes])]] if gt_boxes else \"no_tumor/empty\"\n",
        "        mean_iou = float(np.mean(ious)) if ious else 0.0\n",
        "\n",
        "        # usa 'writer' agora\n",
        "        writer.writerow([img_path.name, len(tps), len(fps), len(fns), f\"{mean_iou:.3f}\", pred_major, gt_major])\n",
        "\n",
        "\n",
        "print(f\"✅ Visualizações salvas em: {OUT_DIR}\")\n",
        "print(f\"CSV resumo: {summary_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwyPOioQAQJ4"
      },
      "source": [
        "# **VISUALIZAÇÃO DE ALGUMAS DAS IMAGENS GERADAS EM TESTE** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:15:22.720899Z",
          "iopub.status.busy": "2025-11-09T18:15:22.720655Z",
          "iopub.status.idle": "2025-11-09T18:15:22.886402Z",
          "shell.execute_reply": "2025-11-09T18:15:22.885703Z",
          "shell.execute_reply.started": "2025-11-09T18:15:22.720878Z"
        },
        "id": "eprPYIGXAQJ4",
        "outputId": "d6e0657a-5ab5-43e9-f9f5-a3cb8359ea0f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for path in glob.glob(\"/content/vis_yolo/*_sidebyside.png\")[5:20]:  # O index das imagens podem ser limitados para visualização de apenas algumas\n",
        "    print(path)\n",
        "    display(Image(filename=path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PskSKaEAQJ4"
      },
      "source": [
        "# **VISUALIZAÇÃO DE PREDIÇÕES COM FALSO POSITIVO E FALSO NEGATIVO** #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-11-09T18:20:41.495286Z",
          "iopub.status.busy": "2025-11-09T18:20:41.494924Z",
          "iopub.status.idle": "2025-11-09T18:20:42.082208Z",
          "shell.execute_reply": "2025-11-09T18:20:42.081486Z",
          "shell.execute_reply.started": "2025-11-09T18:20:41.495262Z"
        },
        "id": "E2QZSG5BAQJ4",
        "outputId": "f2d2da5e-3304-4fca-9641-87a859bf64a5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, Image\n",
        "from pathlib import Path\n",
        "\n",
        "# Ler resumo\n",
        "df = pd.read_csv(summary_csv)\n",
        "erros = df[(df['fp'] > 0) | (df['fn'] > 0)].copy()\n",
        "print(f\"Total de imagens com erro: {len(erros)}\")\n",
        "display(erros.head(10))  # mostra a tabela no topo (pode manter)\n",
        "\n",
        "# Exibir cada linha com sua imagem correspondente\n",
        "print(\"\\n=== Imagens com erro (FP/FN destacados) ===\")\n",
        "\n",
        "for _, row in erros.iterrows():\n",
        "    img_name = Path(row[\"image\"]).stem\n",
        "    img_path = OUT_DIR / f\"{img_name}_sidebyside.png\"\n",
        "    if img_path.exists():\n",
        "        print(f\"\\n{row['image']} | TP={row['tp']} FP={row['fp']} FN={row['fn']} | mean IoU={row['mean_iou_TP']}\")\n",
        "        print(f\"Pred: {row['pred_major(label,score)']} | GT: {row['gt_major(label)']}\")\n",
        "        display(Image(filename=str(img_path)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULDyZrn0ftJ0"
      },
      "source": [
        "# **CONCLUSÕES**\n",
        "\n",
        "Este estudo experimental teve como objetivo comparar duas arquiteturas de Aprendizado Profundo  para a análise de imagens de ressonância magnética cerebral: (1) uma CNN de Classificação, focada em identificar o tipo de tumor, e (2) um modelo YOLO (Arquitetura 2), focado na deteção e localização do tumor. A CNN de Classificação (Arquitetura 1) alcançou um desempenho robusto na sua tarefa, com uma Acurácia de 95.79% e um F1-Score (macro) de 0.96. Em paralelo, o modelo YOLO (Arquitetura 2) alcançou um mAP (mean Average Precision) de 0.9566 na tarefa de deteção, demonstrando a viabilidade de localizar as lesões em tempo real.\n",
        "\n",
        "Embora ambas as arquiteturas tenham apresentado resultados promissores, a análise crítica  revela trade-offs significativos.\n",
        "\n",
        "* CNN (Arquitetura 1): A análise da matriz de confusão e das amostras de erro  mostrou que a CNN teve maior dificuldade em diferenciar as classes Meningioma e Glioma, que são visualmente similares. A sua principal limitação é a necessidade de que a imagem de entrada já esteja \"focada\" no tumor.\n",
        "\n",
        "\n",
        "*   YOLO (Arquitetura 2): O YOLO, por outro lado, conseguiu localizar corretamente os tumores mesmo em imagens complexas. Porém, é possivel observar maiores erros em relação a classe Glioma, contudo esses erros podem ser em decorrencia do dataset, ja que é uma arquitetura supervisionada no qual é feito identificação de cada classe manualmente. E visualmente, é possivel detectar a identificação de falsos positivos reportados pela análise, que na verdade o modelo identificou corretamente, porém no dataset não estavam bem identificados.\n",
        "\n",
        "O custo computacional e de implementação diferiu substancialmente. A CNN de Classificação teve um tempo de treino médio de 5.61 segundos por época  e exigiu um pipeline de dados simples (imagens por pasta). O YOLO, contudo, teria exigido um pré-processamento de dados muito mais complexo, a anotação de bounding boxes, entretanto foi encontrado um dataset já anotado. O custo computacional do treinamento do YOLO foi de 66 segundos por época.\n",
        "\n",
        "Em conclusão, este estudo demonstrou que não há uma única \"melhor\" arquitetura, mas sim a arquitetura \"certa\" para a tarefa. Para uma triagem rápida, a CNN de Classificação é eficiente. No entanto, para um auxílio diagnóstico clínico, que exige localização, o YOLO é superior.\n",
        "\n",
        "Como próximos passos, propõe-se a implementação de um pipeline híbrido: usar o YOLO (Arquitetura 2) para primeiro detetar e recortar a região de interesse, e então alimentar essa região recortada na CNN de Classificação (Arquitetura 1) para obter uma classificação mais precisa.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
